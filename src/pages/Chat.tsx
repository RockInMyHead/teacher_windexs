import React, { useState, useRef, useEffect } from 'react';
import { Button } from '@/components/ui/button';
import { Input } from '@/components/ui/input';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { ScrollArea } from '@/components/ui/scroll-area';
import { Avatar, AvatarFallback } from '@/components/ui/avatar';
import { Brain, Send, User, MessageCircle, Upload, FileText, Image, File, X, Camera, Volume2, VolumeX, Mic, MicOff, ArrowLeft } from 'lucide-react';
import { useNavigate } from 'react-router-dom';
import { useAuth } from '@/contexts/AuthContext';
import { OpenAITTS, isTTSAvailable } from '@/lib/openaiTTS';
import { runAdaptiveAssessment, AssessmentResult, AssessmentQuestion } from '@/utils/adaptiveAssessment';
import { LessonContextManager, LessonContext, LessonBlock } from '@/utils/lessonContextManager';

// Global types for Speech Recognition API
interface SpeechRecognitionEvent extends Event {
  resultIndex: number;
  results: SpeechRecognitionResultList;
}

interface SpeechRecognitionResultList {
  [index: number]: SpeechRecognitionResult;
  length: number;
}

interface SpeechRecognitionResult {
  [index: number]: SpeechRecognitionAlternative;
  length: number;
  isFinal: boolean;
}

interface SpeechRecognitionAlternative {
  transcript: string;
  confidence: number;
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  start(): void;
  stop(): void;
  onstart: ((event: Event) => void) | null;
  onresult: ((event: SpeechRecognitionEvent) => void) | null;
  onerror: ((event: any) => void) | null;
  onend: ((event: Event) => void) | null;
}



interface Message {
  id: string;
  role: 'user' | 'assistant';
  content: string;
  timestamp: Date;
  ttsPlayed?: boolean;
}

declare global {
  interface Window {
    _assessmentResolver?: ((answer: string) => void) | null;
  }
}



const Chat = () => {
  const { isAuthenticated } = useAuth();
  const navigate = useNavigate();
  const [messages, setMessages] = useState<Message[]>([]);
  const [inputMessage, setInputMessage] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [uploadedFiles, setUploadedFiles] = useState<File[]>([]);
  
  // Adaptive assessment states
  const [isInAdaptiveMode, setIsInAdaptiveMode] = useState(false);
  const [assessmentState, setAssessmentState] = useState<'initial' | 'collecting_grade' | 'collecting_topic' | 'in_progress' | 'completed'>('initial');
  const [classGrade, setClassGrade] = useState('');
  const [lastTopic, setLastTopic] = useState('');
  const [currentAssessmentQuestion, setCurrentAssessmentQuestion] = useState<AssessmentQuestion | null>(null);
  const [assessmentResult, setAssessmentResult] = useState<AssessmentResult | null>(null);
  const [questionCount, setQuestionCount] = useState(0);
  const [isProcessingFile, setIsProcessingFile] = useState(false);
  const [isCameraActive, setIsCameraActive] = useState(false);
  const [cameraStream, setCameraStream] = useState<MediaStream | null>(null);
  const [capturedImage, setCapturedImage] = useState<string | null>(null);
  const [speakingMessageId, setSpeakingMessageId] = useState<string | null>(null);
  const [isTtsEnabled, setIsTtsEnabled] = useState(false);
  const [isVoiceChatActive, setIsVoiceChatActive] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [apiKeyStatus, setApiKeyStatus] = useState<'checking' | 'valid' | 'invalid' | 'error'>('checking');
  const [ttsInterrupted, setTtsInterrupted] = useState(false);
  const [currentSentence, setCurrentSentence] = useState<number>(0);
  const [totalSentences, setTotalSentences] = useState<number>(0);
  const [isGeneratingTTS, setIsGeneratingTTS] = useState(false);
  const [showSphere, setShowSphere] = useState(false);
  const [isAudioTaskActive, setIsAudioTaskActive] = useState(false);
  const [audioTaskText, setAudioTaskText] = useState('');
  const [isRecordingAudioTask, setIsRecordingAudioTask] = useState(false);
  const [isTestQuestionActive, setIsTestQuestionActive] = useState(false);
  const [testQuestionData, setTestQuestionData] = useState<{
    question: string;
    options: string[];
    currentQuestion: number;
    totalQuestions: number;
  } | null>(null);

  // Lesson context management
  const [lessonContextManager] = useState(() => new LessonContextManager());
  const [isLessonMode, setIsLessonMode] = useState(false);
  const scrollAreaRef = useRef<HTMLDivElement>(null);
  const inputRef = useRef<HTMLInputElement>(null);
  const fileInputRef = useRef<HTMLInputElement>(null);
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const recognitionRef = useRef<any>(null);
  const ttsContinueRef = useRef<boolean>(true);
  const audioContextRef = useRef<AudioContext | null>(null);
  const currentAudioRef = useRef<HTMLAudioElement | null>(null);
  const soundIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const interruptionCheckIntervalsRef = useRef<Set<NodeJS.Timeout>>(new Set());

  // Audio feedback functions
  const initAudioContext = () => {
    if (!audioContextRef.current) {
      audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)();
    }
    return audioContextRef.current;
  };

  const playBeep = async (frequency: number = 800, duration: number = 200, type: OscillatorType = 'sine') => {
    try {
      const audioContext = initAudioContext();
      if (audioContext.state === 'suspended') {
        await audioContext.resume();
      }

      const oscillator = audioContext.createOscillator();
      const gainNode = audioContext.createGain();

      oscillator.connect(gainNode);
      gainNode.connect(audioContext.destination);

      oscillator.frequency.value = frequency;
      oscillator.type = type;

      gainNode.gain.setValueAtTime(0.1, audioContext.currentTime);
      gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + duration / 1000);

      oscillator.start(audioContext.currentTime);
      oscillator.stop(audioContext.currentTime + duration / 1000);
    } catch (error) {
      console.warn('Could not play audio feedback:', error);
    }
  };

  const startContinuousSound = (frequency: number = 600, interval: number = 800) => {
    if (soundIntervalRef.current) {
      clearInterval(soundIntervalRef.current);
    }

    soundIntervalRef.current = setInterval(() => {
      playBeep(frequency, 100, 'sine');
    }, interval);
  };


  const stopContinuousSound = () => {
    if (soundIntervalRef.current) {
      clearInterval(soundIntervalRef.current);
      soundIntervalRef.current = null;
    }
  };

  // Clear all interruption check intervals
  const clearAllInterruptionChecks = () => {
    interruptionCheckIntervalsRef.current.forEach(interval => {
      clearInterval(interval);
    });
    interruptionCheckIntervalsRef.current.clear();
  };


  // Auto TTS for new messages when enabled
  useEffect(() => {
    if (isTtsEnabled && messages.length > 0) {
      const lastMessage = messages[messages.length - 1];
      // Only auto-speak assistant messages, not user messages, and only if not already speaking
      if (lastMessage.role === 'assistant' && !lastMessage.ttsPlayed && !OpenAITTS.isPlaying()) {
        // Mark as played to avoid re-playing
        lastMessage.ttsPlayed = true;
        speakTextBySentences(lastMessage.content, lastMessage.id); // Use sentence-by-sentence speaking
      }
    }
  }, [messages, isTtsEnabled]);

  // Initialize Speech Recognition
  useEffect(() => {
    console.log('üé§ Initializing Speech Recognition...');

    // Try different ways to access Speech Recognition API
    let SpeechRecognitionConstructor: any = null;

    if ((window as any).SpeechRecognition) {
      SpeechRecognitionConstructor = (window as any).SpeechRecognition;
      console.log('‚úÖ Found SpeechRecognition');
    } else if ((window as any).webkitSpeechRecognition) {
      SpeechRecognitionConstructor = (window as any).webkitSpeechRecognition;
      console.log('‚úÖ Found webkitSpeechRecognition');
    } else if ((window as any).mozSpeechRecognition) {
      SpeechRecognitionConstructor = (window as any).mozSpeechRecognition;
      console.log('‚úÖ Found mozSpeechRecognition');
    } else if ((window as any).msSpeechRecognition) {
      SpeechRecognitionConstructor = (window as any).msSpeechRecognition;
      console.log('‚úÖ Found msSpeechRecognition');
    }

    if (SpeechRecognitionConstructor) {
      try {
        recognitionRef.current = new SpeechRecognitionConstructor();
        recognitionRef.current.continuous = false;
        recognitionRef.current.interimResults = false;
        recognitionRef.current.lang = 'ru-RU';
        console.log('‚úÖ Speech Recognition initialized successfully');
      } catch (error) {
        console.error('‚ùå Error initializing Speech Recognition:', error);
      }
    } else {
      console.log('‚ùå No Speech Recognition API found');
    }
  }, []);

  // Cleanup camera, TTS and speech recognition on unmount
  useEffect(() => {
    return () => {
      if (cameraStream) {
        cameraStream.getTracks().forEach(track => track.stop());
      }
      // Stop TTS
      OpenAITTS.stop();
      // Stop speech recognition
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
    };
  }, [cameraStream]);


  // Function to split text into sentences
  const splitIntoSentences = (text: string): string[] => {
    // Split by sentence endings, but keep the punctuation
    const sentences = text.split(/(?<=[.!?])\s+/);
    return sentences.filter(sentence => sentence.trim().length > 0);
  };

  // Function to speak text sentence by sentence for faster TTS
  const speakTextBySentences = async (text: string, messageId: string) => {
    if (!isTTSAvailable()) {
      alert('OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è.');
      return;
    }

    ttsContinueRef.current = true; // Reset continuation flag

    try {
      // Stop any currently speaking
      OpenAITTS.stop();
      if (currentAudioRef.current) {
        currentAudioRef.current.pause();
        currentAudioRef.current.currentTime = 0;
        currentAudioRef.current = null;
      }

      setSpeakingMessageId(messageId);
      setIsGeneratingTTS(true);

      // Split text into sentences
      const sentences = splitIntoSentences(text).filter(s => s.trim().length > 0);
      console.log('üìù Split into sentences:', sentences);

      if (sentences.length === 0) {
        setSpeakingMessageId(null);
        setIsGeneratingTTS(false);
        return;
      }

      // Set total sentences for UI
      setTotalSentences(sentences.length);
      setCurrentSentence(0);

      console.log('üöÄ Starting parallel TTS generation for', sentences.length, 'sentences');

      // Start continuous TTS generation sound (same pattern as LLM)
      startContinuousSound(500, 1800);

      // Generate all audio buffers in parallel
      const generationPromises = sentences.map(async (sentence, index) => {
        try {
          console.log(`üì§ Generating TTS for sentence ${index + 1}:`, sentence.substring(0, 50) + '...');
          const audioBuffer = await OpenAITTS.generateSpeech(sentence, {
            voice: 'alloy',
            speed: 0.9,
            model: 'tts-1'
          });
          console.log(`‚úÖ TTS generated for sentence ${index + 1}`);
          return { audioBuffer, sentence, index };
        } catch (error) {
          console.error(`‚ùå Failed to generate TTS for sentence ${index + 1}:`, error);
          return { audioBuffer: null, sentence, index, error };
        }
      });

      // Wait for all generations to complete
      const audioResults = await Promise.allSettled(generationPromises);
      const successfulResults = audioResults
        .filter((result): result is PromiseFulfilledResult<{ audioBuffer: ArrayBuffer | null; sentence: string; index: number; error?: any }> =>
          result.status === 'fulfilled' && result.value.audioBuffer !== null
        )
        .map(result => result.value);

      console.log('üéâ All TTS generation completed');

      // Stop continuous TTS generation sound
      stopContinuousSound();

      // Helper function to play a sentence
      const playSentence = async (audioBuffer: ArrayBuffer, sentence: string, sentenceNumber: number, totalSentences: number): Promise<void> => {
        return new Promise<void>((resolve, reject) => {
          // Check if TTS was interrupted before starting playback
          if (!ttsContinueRef.current) {
            console.log('üõë TTS interrupted before playback');
            reject(new Error('TTS interrupted'));
            return;
          }

          setCurrentSentence(sentenceNumber);
          console.log(`üîä Playing sentence ${sentenceNumber}/${totalSentences}:`, sentence.substring(0, 50) + '...');

          // Silent playback

          try {
            const blob = new Blob([audioBuffer], { type: 'audio/mpeg' });
            const audioUrl = URL.createObjectURL(blob);
            const audio = new Audio(audioUrl);

            const checkInterruption = () => {
              if (!ttsContinueRef.current) {
                console.log('üõë TTS interrupted during playback');
                audio.pause();
                URL.revokeObjectURL(audioUrl);
                currentAudioRef.current = null;
                reject(new Error('TTS interrupted'));
              }
            };

            // Check for interruption every 100ms
            const interruptionCheck = setInterval(checkInterruption, 100);
            // Register the interval for cleanup
            interruptionCheckIntervalsRef.current.add(interruptionCheck);

            audio.onended = () => {
              clearInterval(interruptionCheck);
              interruptionCheckIntervalsRef.current.delete(interruptionCheck);
              URL.revokeObjectURL(audioUrl);
              currentAudioRef.current = null;
              resolve();
            };

            audio.onerror = (error) => {
              clearInterval(interruptionCheck);
              interruptionCheckIntervalsRef.current.delete(interruptionCheck);
              URL.revokeObjectURL(audioUrl);
              currentAudioRef.current = null;
              reject(error);
            };

            // Store reference to current audio for interruption
            currentAudioRef.current = audio;

            audio.play().catch((error) => {
              clearInterval(interruptionCheck);
              interruptionCheckIntervalsRef.current.delete(interruptionCheck);
              URL.revokeObjectURL(audioUrl);
              currentAudioRef.current = null;
              reject(error);
            });
          } catch (playError) {
            console.error(`Error setting up audio for sentence ${sentenceNumber}:`, playError);
            reject(playError);
          }
        });
      };

      // Play sentences sequentially
      for (let i = 0; i < successfulResults.length; i++) {
        const result = successfulResults[i];

        // Check if TTS was interrupted before starting next sentence
        if (!ttsContinueRef.current) {
          console.log('üõë TTS interrupted before playing sentence', i + 1);
          break;
        }

        try {
          await playSentence(result.audioBuffer!, result.sentence, i + 1, successfulResults.length);

          // Small pause between sentences (only if not interrupted)
          if (i < successfulResults.length - 1 && ttsContinueRef.current) {
            await new Promise<void>((resolve, reject) => {
              const pauseCheck = setInterval(() => {
                if (!ttsContinueRef.current) {
                  clearInterval(pauseCheck);
                  interruptionCheckIntervalsRef.current.delete(pauseCheck);
                  reject(new Error('TTS interrupted during pause'));
                }
              }, 50);

              // Register the pause check interval
              interruptionCheckIntervalsRef.current.add(pauseCheck);

              setTimeout(() => {
                clearInterval(pauseCheck);
                interruptionCheckIntervalsRef.current.delete(pauseCheck);
                if (ttsContinueRef.current) {
                  resolve();
    } else {
                  reject(new Error('TTS interrupted during pause'));
                }
              }, 150);
            });
          }
        } catch (playError) {
          if (playError.message === 'TTS interrupted') {
            console.log('üõë TTS playback interrupted by user');
            break;
          }
          console.error(`Error playing sentence ${i + 1}:`, playError);
          // Continue with next sentence
        }
      }

      // Reset counters and state only if not interrupted
      if (ttsContinueRef.current) {
        setCurrentSentence(0);
        setTotalSentences(0);
        setIsGeneratingTTS(false);
        setSpeakingMessageId(null);
      }

    } catch (error) {
      console.error('Parallel TTS error:', error);
      alert('–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ—á–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.');
      setSpeakingMessageId(null);
      setCurrentSentence(0);
      setTotalSentences(0);
      setIsGeneratingTTS(false);
    }
  };

  // Function to speak text using OpenAI TTS (legacy function)
  const speakText = async (text: string, messageId: string, showVisualFeedback: boolean = true) => {
    if (!isTTSAvailable()) {
      alert('OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è.');
      return;
    }

    try {
      // Stop any currently speaking
      OpenAITTS.stop();

      if (showVisualFeedback && speakingMessageId === messageId) {
        // If already speaking this message, stop it
        setSpeakingMessageId(null);
        return;
      }

      if (showVisualFeedback) {
        setSpeakingMessageId(messageId);
      }

      // Use sentence-by-sentence speaking for better performance
      await speakTextBySentences(text, messageId);

    } catch (error) {
      console.error('OpenAI TTS error:', error);
      alert('–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ—á–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.');
      if (showVisualFeedback) {
        setSpeakingMessageId(null);
      }
    }
  };

  // Function to toggle TTS mode
  const toggleTts = () => {
    if (isTtsEnabled) {
      // Disable TTS
      setIsTtsEnabled(false);
      setSpeakingMessageId(null);
      OpenAITTS.stop();
    } else {
      // Enable TTS
      setIsTtsEnabled(true);
    }
  };

  // Function to start voice chat
  const startVoiceChat = async () => {
    setShowSphere(true);
    console.log('üöÄ Starting voice chat...');
    console.log('üîç isTTSAvailable():', isTTSAvailable());
    console.log('üîç Speech Recognition available:', 'webkitSpeechRecognition' in window && 'SpeechRecognition' in window);
    console.log('üîç OpenAI API key:', import.meta.env.VITE_OPENAI_API_KEY ? 'present' : 'missing');
    console.log('üîç VITE_OPENAI_API_KEY value:', import.meta.env.VITE_OPENAI_API_KEY);

    // No start sound - keeping it silent

    if (!isTTSAvailable()) {
      alert('OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è.');
      console.log('‚ùå OpenAI API key not available');
      return;
    }

    console.log('‚úÖ OpenAI API key available');

    console.log('üîç Checking Speech Recognition support...');
    console.log('webkitSpeechRecognition in window:', 'webkitSpeechRecognition' in window);
    console.log('SpeechRecognition in window:', 'SpeechRecognition' in window);
    console.log('navigator.userAgent:', navigator.userAgent);
    console.log('location.protocol:', location.protocol);

    if (!recognitionRef.current) {
      const userAgent = navigator.userAgent;
      const browserName = userAgent.includes('Firefox') ? 'Firefox' :
                         userAgent.includes('Chrome') ? 'Chrome' :
                         userAgent.includes('Safari') && !userAgent.includes('Chrome') ? 'Safari' :
                         userAgent.includes('Edge') ? 'Edge' : '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –±—Ä–∞—É–∑–µ—Ä';

      const isHTTPS = location.protocol === 'https:';
      const isLocalhost = location.hostname === 'localhost' || location.hostname === '127.0.0.1';

      let reason = '';
      if (!isHTTPS && !isLocalhost) {
        reason = '\n\n–ü—Ä–∏—á–∏–Ω–∞: Web Speech API —Ç—Ä–µ–±—É–µ—Ç HTTPS —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è.';
      } else if (browserName === 'Safari') {
        reason = '\n\n–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: Safari –º–æ–∂–µ—Ç —Ç—Ä–µ–±–æ–≤–∞—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–π –∏–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è.';
      }

      const choice = confirm(`üé§ –í–∞—à –±—Ä–∞—É–∑–µ—Ä (${browserName}) –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏.${reason}\n\n–î–æ—Å—Ç—É–ø–Ω—ã–µ API:\n‚Ä¢ webkitSpeechRecognition: ${'webkitSpeechRecognition' in window}\n‚Ä¢ SpeechRecognition: ${'SpeechRecognition' in window}\n\n–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º:\n\n‚Ä¢ OK: –¢–µ–∫—Å—Ç–æ–≤—ã–π –≤–≤–æ–¥ —Å –≥–æ–ª–æ—Å–æ–≤—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏\n‚Ä¢ –û—Ç–º–µ–Ω–∞: –¢–æ–ª—å–∫–æ TTS –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è`);

      if (choice) {
        // –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º —Å TTS –æ—Ç–≤–µ—Ç–∞–º–∏
        alert('‚úçÔ∏è –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω!\n\n–ü–∏—à–∏—Ç–µ –≤–æ–ø—Ä–æ—Å—ã –≤ —á–∞—Ç–µ - AI –±—É–¥–µ—Ç –æ—Ç–≤–µ—á–∞—Ç—å –≥–æ–ª–æ—Å–æ–º.\n\n–î–ª—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ–±—â–µ–Ω–∏—è —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Chrome –∏–ª–∏ Edge.');
        setIsTtsEnabled(true);
        console.log('üìù Text mode with TTS enabled');
      } else {
        // –¢–æ–ª—å–∫–æ TTS –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤
        alert('üîä TTS —Ä–µ–∂–∏–º –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω!\n\nAI –±—É–¥–µ—Ç –æ–∑–≤—É—á–∏–≤–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–∞—à–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è.\n\n–î–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–≤–æ–¥–∞ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Chrome –∏–ª–∏ Edge.');
        setIsTtsEnabled(true);
        console.log('üîä TTS-only mode enabled');
      }
      return;
    }

    console.log('üîç Checking SpeechRecognition availability...');
    if (!recognitionRef.current) {
      console.log('‚ùå SpeechRecognition not initialized');
      alert('–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É.');
      return;
    }
    console.log('‚úÖ SpeechRecognition initialized');

    if (isVoiceChatActive) {
      // Stop voice chat
      setIsVoiceChatActive(false);
      setIsListening(false);
      recognitionRef.current.stop();
      OpenAITTS.stop();
      return;
    }

    // Start voice chat
    setIsVoiceChatActive(true);
    setIsListening(true);

    try {
      // Configure for continuous listening with interim results
      recognitionRef.current.continuous = true;
      recognitionRef.current.interimResults = true;

      let isProcessing = false;
      let finalTranscript = '';
      let interimTranscript = '';

      recognitionRef.current.onresult = async (event) => {
        interimTranscript = '';
        finalTranscript = '';

        // Process all results
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalTranscript += transcript;
          } else {
            interimTranscript += transcript;
          }
        }

        console.log('Final:', finalTranscript, 'Interim:', interimTranscript);

        // Interrupt TTS immediately when user starts speaking (even with minimal interim results)
        const shouldInterrupt = (interimTranscript.trim() && interimTranscript.trim().length > 0) ||
                               (finalTranscript.trim() && finalTranscript.trim().length > 0);

        if (shouldInterrupt && (currentAudioRef.current || isGeneratingTTS || speakingMessageId)) {
          console.log('üõë Interrupting TTS - user started speaking');

          // Stop current audio playback
          if (currentAudioRef.current) {
            currentAudioRef.current.pause();
            currentAudioRef.current.currentTime = 0;
            currentAudioRef.current = null;
          }

          // Stop TTS generation and playback
          OpenAITTS.stop();
          ttsContinueRef.current = false;

          // Stop continuous sound if playing
          stopContinuousSound();

          // Clear all interruption check intervals
          clearAllInterruptionChecks();

          // Reset TTS state
          setIsGeneratingTTS(false);
          setSpeakingMessageId(null);
          setCurrentSentence(0);
          setTotalSentences(0);
          setTtsInterrupted(true);

          // Reset interruption flag after delay
          setTimeout(() => setTtsInterrupted(false), 1000);

          console.log('‚úÖ TTS interrupted successfully');
        }

        // If we have a final transcript and not currently processing
        if (finalTranscript.trim() && !isProcessing) {
          isProcessing = true;
          setIsListening(false);

          try {
            // Add user message
            const userMessage: Message = {
              id: Date.now().toString(),
              role: 'user',
              content: finalTranscript.trim(),
              timestamp: new Date(),
            };

            setMessages(prev => [...prev, userMessage]);
            setIsLoading(true);

            // Start continuous thinking sound while AI generates response
            startContinuousSound(500, 1800);

            // Get AI response using GPT-3.5-turbo for faster response with fallback

            // –°–æ–∑–¥–∞—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —á–∞—Ç–∞
            const voiceSystemPrompt = `–í—ã - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ–¥–∞–≥–æ–≥ –∏ —ç–∫—Å–ø–µ—Ä—Ç –≤ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏. –í–∞—à–∞ –∑–∞–¥–∞—á–∞ - –æ–±—ä—è—Å–Ω—è—Ç—å –ª—é–±—ã–µ —Ç–µ–º—ã –±—ã—Å—Ç—Ä–æ, –ø–æ–Ω—è—Ç–Ω–æ –∏ –¥–æ—Å—Ç—É–ø–Ω–æ. –î–∞–≤–∞–π—Ç–µ –∫—Ä–∞—Ç–∫–∏–µ, –Ω–æ –ø–æ–ª–Ω—ã–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è.

–í–ê–ñ–ù–û: –ü–∏—à–∏—Ç–µ –í–°–ï —á–∏—Å–ª–∞, –¥–∞—Ç—ã, –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞–∫–∏ –∏ –æ–ø–µ—Ä–∞—Ü–∏–∏ –ë–£–ö–í–ê–ú–ò, –∞ –Ω–µ —Ü–∏—Ñ—Ä–∞–º–∏!

–ü—Ä–∞–≤–∏–ª–∞ –Ω–∞–ø–∏—Å–∞–Ω–∏—è:
- –ß–∏—Å–ª–∞: "–¥–≤–∞–¥—Ü–∞—Ç—å —Ç—Ä–∏" –≤–º–µ—Å—Ç–æ "23", "—Å—Ç–æ –ø—è—Ç—å–¥–µ—Å—è—Ç" –≤–º–µ—Å—Ç–æ "150"
- –î–∞—Ç—ã: "–¥–≤–µ–Ω–∞–¥—Ü–∞—Ç–æ–µ –∞–ø—Ä–µ–ª—è —Ç—ã—Å—è—á–∞ –¥–µ–≤—è—Ç—å—Å–æ—Ç —à–µ—Å—Ç—å–¥–µ—Å—è—Ç –ø–µ—Ä–≤–æ–≥–æ –≥–æ–¥–∞" –≤–º–µ—Å—Ç–æ "12 –∞–ø—Ä–µ–ª—è 1961 –≥–æ–¥–∞"
- –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞: "–¥–≤–∞ –ø–ª—é—Å —Ç—Ä–∏ —Ä–∞–≤–Ω–æ –ø—è—Ç–∏" –≤–º–µ—Å—Ç–æ "2 + 3 = 5"
- –ü—Ä–æ—Ü–µ–Ω—Ç—ã: "—Ç—Ä–∏–¥—Ü–∞—Ç—å –ø—è—Ç—å –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤" –≤–º–µ—Å—Ç–æ "35%"
- –î—Ä–æ–±–∏: "—Ç—Ä–∏ –ø—è—Ç—ã—Ö" –≤–º–µ—Å—Ç–æ "3/5"
- –°—Ç–µ–ø–µ–Ω–∏: "–¥–≤–∞ –≤ –∫—É–±–µ" –≤–º–µ—Å—Ç–æ "2¬≥"
- –ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ: "–ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏–∏ —ç—Ñ –æ—Ç –∏–∫—Å" –∏–ª–∏ "–¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª –∏–≥—Ä–µ–∫ –ø–æ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª –∏–∫—Å" –≤–º–µ—Å—Ç–æ "f'(x)" –∏–ª–∏ "dy/dx"
- –ò–Ω—Ç–µ–≥—Ä–∞–ª—ã: "–∏–Ω—Ç–µ–≥—Ä–∞–ª –æ—Ç –Ω—É–ª—è –¥–æ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–∏" –≤–º–µ—Å—Ç–æ "‚à´‚àû0"
- –°—É–º–º—ã: "—Å—É–º–º–∞ –æ—Ç –∏ —Ä–∞–≤–Ω—è–µ—Ç—Å—è –µ–¥–∏–Ω–∏—Ü–µ –¥–æ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–∏" –≤–º–µ—Å—Ç–æ "‚àë‚àûi=1"
- –ì—Ä–µ—á–µ—Å–∫–∏–µ –±—É–∫–≤—ã: "–ø–∏", "—Å–∏–≥–º–∞", "–¥–µ–ª—å—Ç–∞" –≤–º–µ—Å—Ç–æ "œÄ", "œÉ", "Œ¥"

–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –≤–∞—à–µ–≥–æ —Å—Ç–∏–ª—è:
- –û–±—ä—è—Å–Ω—è–π—Ç–µ —Å–ª–æ–∂–Ω–æ–µ –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–∏–º–µ—Ä—ã –∏ –∞–Ω–∞–ª–æ–≥–∏–∏
- –ë—É–¥—å—Ç–µ –∫—Ä–∞—Ç–∫–∏, –Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã
- –ó–∞–¥–∞–≤–∞–π—Ç–µ –Ω–∞–≤–æ–¥—è—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è
- –ê–¥–∞–ø—Ç–∏—Ä—É–π—Ç–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –ø–æ–¥ —É—Ä–æ–≤–µ–Ω—å —É—á–µ–Ω–∏–∫–∞

–ö–†–ò–¢–ò–ß–ù–û –í–ê–ñ–ù–û –î–õ–Ø –ì–û–õ–û–°–û–í–û–ì–û –ß–ê–¢–ê: –ê–ö–¢–ò–í–ù–û –ò–°–ü–û–õ–¨–ó–£–ô–¢–ï –ò–°–¢–û–†–ò–Æ –ë–ï–°–ï–î–´!
- –í—Å–µ–≥–¥–∞ —Å—Å—ã–ª–∞–π—Ç–µ—Å—å –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ä–∞–∑–≥–æ–≤–æ—Ä–µ
- –ü–æ–º–Ω–∏—Ç–µ, —á—Ç–æ –æ–±—Å—É–∂–¥–∞–ª–æ—Å—å —Ä–∞–Ω–µ–µ –≤ —ç—Ç–æ–π –±–µ—Å–µ–¥–µ
- –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –ª–æ–≥–∏—á–µ—Å–∫—É—é –Ω–∏—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
- –ò–∑–±–µ–≥–∞–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π —É–∂–µ –æ–±—ä—è—Å–Ω–µ–Ω–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ—Ä–∞–∑—ã —Ç–∏–ø–∞ "–∫–∞–∫ –º—ã —Ç–æ–ª—å–∫–æ —á—Ç–æ –æ–±—Å—É–∂–¥–∞–ª–∏", "–ø—Ä–æ–¥–æ–ª–∂–∞—è –Ω–∞—à—É —Ç–µ–º—É", "–Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è"
- –û—Ç–≤–µ—á–∞–π—Ç–µ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –≤—Å–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞, –∞ –Ω–µ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ

–°–¢–†–£–ö–¢–£–†–ê –ì–û–õ–û–°–û–í–û–ì–û –£–†–û–ö–ê:
–ì–æ–ª–æ—Å–æ–≤–æ–π —á–∞—Ç –ù–ï –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ —Ç–µ—Å—Ç—ã, –ø–æ—ç—Ç–æ–º—É:
- –ó–∞–¥–∞–≤–∞–π—Ç–µ —É—Å—Ç–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ –∂–¥–∏—Ç–µ –æ—Ç–≤–µ—Ç–æ–≤ —É—á–µ–Ω–∏–∫–∞
- –î–∞–≤–∞–π—Ç–µ –∫—Ä–∞—Ç–∫–∏–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
- –ü—Ä–æ–≤–æ–¥–∏—Ç–µ –±–µ—Å–µ–¥—É –≤ —Ñ–æ—Ä–º–∞—Ç–µ "–≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç"
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π—Ç–µ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–π —Å—Ç–∏–ª—å
- –ü–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Å–ø—Ä–∞—à–∏–≤–∞–π—Ç–µ: "–ü–æ–Ω—è—Ç–Ω–æ? –ï—Å—Ç—å –≤–æ–ø—Ä–æ—Å—ã?"

–ü–∞–º—è—Ç—å –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç: –ò—Å—Ç–æ—Ä–∏—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 30 —Å–æ–æ–±—â–µ–Ω–∏–π –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –≤–∞–º. –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –µ—ë!`;


            let response;
            try {
              response = await fetch(`${window.location.origin}/api/chat/completions`, {
                method: 'POST',
                headers: {
                  'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                  model: 'gpt-3.5-turbo',
                  messages: [
                    {
                      role: 'system',
                      content: voiceSystemPrompt,
                    },
                    ...messages.slice(-30).map(msg => ({ // Keep last 30 messages for teacher memory context
                      role: msg.role,
                      content: msg.content,
                    })),
                    {
                      role: 'user',
                      content: finalTranscript.trim(),
                    },
                  ],
                  max_tokens: 1000, // Increased for extended teacher memory context with 30 messages
                  temperature: 0.7,
                }),
              });
            } catch (fetchError) {
              console.error('Fetch error:', fetchError);
              throw new Error('–û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏ –∫ OpenAI');
            }

            if (!response.ok) {
              const errorData = await response.json().catch(() => ({}));
              console.error('OpenAI API Error:', {
                status: response.status,
                statusText: response.statusText,
                error: errorData
              });

              // Handle specific error codes
              if (response.status === 401) {
                throw new Error('–ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á OpenAI. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.');
              } else if (response.status === 429) {
                throw new Error('–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ OpenAI. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.');
              } else if (response.status === 500) {
                throw new Error('–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ OpenAI. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.');
              } else {
                throw new Error(`–û—à–∏–±–∫–∞ OpenAI: ${response.status} ${response.statusText}`);
              }
            }

            const data = await response.json();

            if (!data.choices || !data.choices[0] || !data.choices[0].message) {
              console.error('Invalid OpenAI response:', data);
              throw new Error('–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç OpenAI');
            }

            const assistantMessage: Message = {
              id: (Date.now() + 1).toString(),
              role: 'assistant',
              content: data.choices[0].message.content,
              timestamp: new Date(),
            };

            // Mark as TTS played to prevent auto-TTS duplication
            assistantMessage.ttsPlayed = true;

            setMessages(prev => [...prev, assistantMessage]);


            // Speak the response sentence by sentence for faster TTS
            await speakTextBySentences(assistantMessage.content, assistantMessage.id);

          } catch (error) {
            console.error('Voice chat error:', error);
            const errorMessage: Message = {
              id: (Date.now() + 1).toString(),
              role: 'assistant',
              content: '–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –≥–æ–≤–æ—Ä–∏—Ç—å.',
              timestamp: new Date(),
            };
            setMessages(prev => [...prev, errorMessage]);
          } finally {
            setIsLoading(false);
            isProcessing = false;
            // Stop continuous thinking sound
            stopContinuousSound();

            // Resume listening after a short delay
            setTimeout(() => {
              if (isVoiceChatActive && recognitionRef.current && !OpenAITTS.isPlaying()) {
                setIsListening(true);
                try {
                  recognitionRef.current.start();
                } catch (e) {
                  // Recognition might already be started, ignore
                }
              }
            }, 500);
          }
        }
      };

      recognitionRef.current.onstart = () => {
        console.log('Speech recognition started');
        setIsListening(true);
      };

      recognitionRef.current.onerror = (event) => {
        console.error('Speech recognition error:', event);
        setIsListening(false);

        // Try to restart listening if it's a non-fatal error
        if (isVoiceChatActive && event.error !== 'not-allowed' && event.error !== 'service-not-allowed') {
          setTimeout(() => {
            if (isVoiceChatActive && recognitionRef.current) {
              try {
                recognitionRef.current.start();
              } catch (e) {
                console.error('Failed to restart recognition:', e);
              }
            }
          }, 1000);
        }
      };

      recognitionRef.current.onend = () => {
        console.log('Speech recognition ended');
        setIsListening(false);

        // Restart listening if voice chat is still active and not speaking
        if (isVoiceChatActive && !OpenAITTS.isPlaying()) {
          setTimeout(() => {
            if (isVoiceChatActive && recognitionRef.current) {
              try {
                setIsListening(true);
                recognitionRef.current.start();
              } catch (e) {
                console.error('Failed to restart recognition:', e);
              }
            }
          }, 300);
        }
      };

      // Start listening
      recognitionRef.current.start();

    } catch (error) {
      console.error('Voice chat start error:', error);
      setIsVoiceChatActive(false);
      setIsListening(false);
      alert('–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ–±—â–µ–Ω–∏—è.');
    }
  };

  // Function to start camera
  const startCamera = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: 'environment' }, // Use back camera if available
        audio: false
      });
      setCameraStream(stream);
      setIsCameraActive(true);

      if (videoRef.current) {
        videoRef.current.srcObject = stream;
      }
    } catch (error) {
      console.error('Error accessing camera:', error);
      alert('–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –∫–∞–º–µ—Ä–µ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è.');
    }
  };

  // Function to stop camera
  const stopCamera = () => {
    if (cameraStream) {
      cameraStream.getTracks().forEach(track => track.stop());
      setCameraStream(null);
    }
    setIsCameraActive(false);
  };

  // Function to capture photo
  const capturePhoto = () => {
    if (!videoRef.current || !canvasRef.current) return;

    const video = videoRef.current;
    const canvas = canvasRef.current;
    const context = canvas.getContext('2d');

    if (!context) return;

    // Set canvas size to video size
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    // Draw video frame to canvas
    context.drawImage(video, 0, 0, canvas.width, canvas.height);

    // Convert to base64
    const imageData = canvas.toDataURL('image/jpeg', 0.8);
    setCapturedImage(imageData);
    stopCamera();
  };

  // Function to retake photo
  const retakePhoto = () => {
    setCapturedImage(null);
    startCamera();
  };

  // Function to send captured photo as task
  const sendCapturedPhoto = async () => {
    if (!capturedImage) return;

    const userMessage: Message = {
      id: Date.now().toString(),
      role: 'user',
      content: '–Ø —Å—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä–æ–≤–∞–ª –∑–∞–¥–∞—á—É. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Ä–µ—à–∏ –µ—ë.',
      timestamp: new Date(),
    };

    setMessages(prev => [...prev, userMessage]);
    setIsLoading(true);

    try {
      // Send photo to OpenAI Vision API for task recognition and solving
      const response = await fetch(`${window.location.origin}/api/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'gpt-4o-mini',
          messages: [
            {
              role: 'system',
              content: `–¢—ã - –æ–ø—ã—Ç–Ω—ã–π –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å –∏ —Ä–µ—à–∞—Ç–µ–ª—å –∑–∞–¥–∞—á. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–∏—Å–ª–∞–ª —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é –∑–∞–¥–∞—á–∏. 
              
–í–ê–ñ–ù–´–ï –ò–ù–°–¢–†–£–ö–¶–ò–ò:
1. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–π —É—á–µ–±–Ω—É—é –∑–∞–¥–∞—á—É
2. –ü–æ–∫–∞–∂–∏ –ø–æ—à–∞–≥–æ–≤–æ–µ —Ä–µ—à–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏
3. –û–±—ä—è—Å–Ω–∏ –∫–∞–∂–¥—ã–π —à–∞–≥ –ø–æ–¥—Ä–æ–±–Ω–æ
4. –ï—Å–ª–∏ –∑–∞–¥–∞—á–∞ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è - –ø–æ–∫–∞–∂–∏ –≤—Å–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
5. –ï—Å–ª–∏ –∑–∞–¥–∞—á–∞ —Ç–µ–∫—Å—Ç–æ–≤–∞—è - —Ä–∞–∑–±–µ—Ä–∏ –µ—ë —Å—Ç—Ä—É–∫—Ç—É—Ä—É
6. –î–∞–π –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
7. –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ—à—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∑–∞–¥–∞—á—É - –ø–æ–ø—Ä–æ—Å–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å–¥–µ–ª–∞—Ç—å –±–æ–ª–µ–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —Ñ–æ—Ç–æ

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
1. **–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–∞—è –∑–∞–¥–∞—á–∞**: [—á—Ç–æ —Ç—ã —É–≤–∏–¥–µ–ª –Ω–∞ —Ñ–æ—Ç–æ]
2. **–†–µ—à–µ–Ω–∏–µ**:
   - –®–∞–≥ 1: [–ø–µ—Ä–≤—ã–π —à–∞–≥]
   - –®–∞–≥ 2: [–≤—Ç–æ—Ä–æ–π —à–∞–≥]
   ...
3. **–û—Ç–≤–µ—Ç**: [—Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç]`,
            },
            {
              role: 'user',
              content: [
                {
                  type: 'text',
                  text: '–†–µ—à–∏ –∑–∞–¥–∞—á—É –Ω–∞ —ç—Ç–æ–π —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏. –ü–æ–∫–∞–∂–∏ –ø–æ–¥—Ä–æ–±–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ.'
                },
                {
                  type: 'image_url',
                  image_url: {
                    url: capturedImage
                  }
                }
              ]
            },
          ],
          max_tokens: 2000,
          temperature: 0.1,
        }),
      });

      if (!response.ok) {
        throw new Error('Failed to analyze photo task');
      }

      const data = await response.json();
      const assistantMessage: Message = {
        id: Date.now().toString(),
        role: 'assistant',
        content: data.choices[0].message.content,
        timestamp: new Date(),
      };
      setMessages(prev => [...prev, assistantMessage]);
    } catch (error) {
      console.error('Error analyzing photo task:', error);
      setMessages(prev => [
        ...prev,
        {
          id: Date.now().toString(),
          role: 'assistant',
          content: '–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –∑–∞–¥–∞—á–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.',
          timestamp: new Date(),
        },
      ]);
    } finally {
      setIsLoading(false);
      setCapturedImage(null);
      if (inputRef.current) {
        inputRef.current.focus();
      }
    }
  };


  // Function to handle file upload
  const handleFileUpload = (event: React.ChangeEvent<HTMLInputElement>) => {
    const files = Array.from(event.target.files || []);
    if (files.length > 0) {
      setUploadedFiles(prev => [...prev, ...files]);
    }
  };

  // Function to remove uploaded file
  const removeFile = (index: number) => {
    setUploadedFiles(prev => prev.filter((_, i) => i !== index));
  };

  // Function to get file icon based on type
  const getFileIcon = (file: File) => {
    const type = file.type;
    if (type.startsWith('image/')) return <Image className="w-4 h-4" />;
    if (type === 'application/pdf') return <FileText className="w-4 h-4" />;
    if (type.includes('word') || type.includes('document')) return <FileText className="w-4 h-4" />;
    return <File className="w-4 h-4" />;
  };

  // Function to extract text from images using OpenAI Vision API
  const extractTextFromImage = async (file: File): Promise<string> => {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = async () => {
        try {
          const base64Image = reader.result as string;

          const response = await fetch(`${window.location.origin}/api/chat/completions`, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              model: 'gpt-4o-mini',
              messages: [
                {
                  role: 'user',
                  content: [
                    {
                      type: 'text',
                      text: '–†–∞—Å–ø–æ–∑–Ω–∞–π –≤–µ—Å—å —Ç–µ–∫—Å—Ç –Ω–∞ —ç—Ç–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏. –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.'
                    },
                    {
                      type: 'image_url',
                      image_url: {
                        url: base64Image
                      }
                    }
                  ]
                }
              ],
              max_tokens: 1000,
              temperature: 0.1,
            }),
          });

          if (!response.ok) {
            throw new Error('Failed to process image with OpenAI');
          }

          const data = await response.json();
          const extractedText = data.choices[0].message.content.trim();

          resolve(extractedText || `–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–µ–∫—Å—Ç –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ ${file.name}.`);
        } catch (error) {
          console.error('OCR Error:', error);
          reject(new Error(`–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞: ${error.message}`));
        }
      };

      reader.onerror = () => reject(new Error('Failed to read file'));
      reader.readAsDataURL(file);
    });
  };

  // Function to extract text from PDF using PDF.js
  const extractTextFromPDF = async (file: File): Promise<string> => {
    try {
      // Dynamic import of PDF.js to avoid bundle bloat
      const pdfjsLib = await import('pdfjs-dist');

      // Set worker source
      pdfjsLib.GlobalWorkerOptions.workerSrc = `//cdnjs.cloudflare.com/ajax/libs/pdf.js/${pdfjsLib.version}/pdf.worker.min.js`;

      const arrayBuffer = await file.arrayBuffer();
      const pdf = await pdfjsLib.getDocument({ data: arrayBuffer }).promise;

      let fullText = '';

      // Extract text from each page
      for (let pageNum = 1; pageNum <= pdf.numPages; pageNum++) {
        const page = await pdf.getPage(pageNum);
        const textContent = await page.getTextContent();

        const pageText = textContent.items
          .map((item: any) => item.str)
          .join(' ');

        fullText += pageText + '\n\n';
      }

      return fullText.trim() || `–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ PDF —Ñ–∞–π–ª–∞ "${file.name}". –í–æ–∑–º–æ–∂–Ω–æ, —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ –∏–º–µ–µ—Ç —Å–ª–æ–∂–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É.`;

    } catch (error) {
      console.error('PDF processing error:', error);
      return `–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ PDF —Ñ–∞–π–ª–∞ "${file.name}": ${error.message}. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –≤—Ä—É—á–Ω—É—é –∏–∑ —Ñ–∞–π–ª–∞.`;
    }
  };

  // Function to extract text from DOCX
  const extractTextFromDOCX = async (file: File): Promise<string> => {
    // For browser environment, we'll use a temporary approach
    // In production, you'd need a server-side solution or a browser-compatible DOCX library
    return new Promise((resolve) => {
      setTimeout(() => {
        resolve(`DOCX —Ñ–∞–π–ª "${file.name}" –ø—Ä–∏–Ω—è—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ Word –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Ç—Ä–µ–±—É–µ—Ç —Å–µ—Ä–≤–µ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏. –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞, –∏–∑–≤–ª–µ—á–µ–Ω–Ω–æ–µ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ.`);
      }, 1500);
    });
  };

  // Function to process file and extract text
  const processFile = async (file: File): Promise<string> => {
    const fileType = file.type;

    if (fileType.startsWith('image/')) {
      return await extractTextFromImage(file);
    } else if (fileType === 'application/pdf') {
      return await extractTextFromPDF(file);
    } else if (fileType.includes('word') || fileType.includes('document')) {
      return await extractTextFromDOCX(file);
    } else {
      return `–§–∞–π–ª ${file.name} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –¥–ª—è OCR.`;
    }
  };

  // Function to parse **bold green text** within a string
  const parseBoldGreenText = (text: string, keyPrefix: string) => {
    const parts = text.split(/(\*\*.*?\*\*)/g);
    return parts.map((part, index) => {
      if (part.startsWith('**') && part.endsWith('**')) {
        // This is a **bold green text** block
        const greenText = part.slice(2, -2); // Remove ** from both sides
        return (
          <span key={`${keyPrefix}-green-${index}`} className="text-green-600 font-semibold">
            {greenText}
          </span>
        );
      }
      // Regular text
      return part;
    });
  };

  // Function to parse and format message content with ### blocks and **green text**
  const formatMessageContent = (content: string) => {
    // Split by lines to process each line individually
    const lines = content.split('\n');
    const result: JSX.Element[] = [];
    let currentBlock: string[] = [];

    lines.forEach((line, index) => {
      if (line.trim().startsWith('### ')) {
        // If we were in a regular block, close it first
        if (currentBlock.length > 0) {
          const blockText = currentBlock.join('\n');
          result.push(
            <span key={`text-${result.length}`} className="whitespace-pre-wrap">
              {parseBoldGreenText(blockText, `text-${result.length}`)}
            </span>
          );
          currentBlock = [];
        }

        // Start or continue a ### block
        const blockContent = line.trim().replace(/^### /, '');
        result.push(
          <div key={`block-${result.length}`} className="text-green-600 font-bold text-lg my-2 bg-green-50 dark:bg-green-950/20 px-3 py-2 rounded-md border-l-4 border-green-500">
            {parseBoldGreenText(blockContent, `block-${result.length}`)}
          </div>
        );
      } else {
        // Regular line
        currentBlock.push(line);
      }
    });

    // Add any remaining regular text
    if (currentBlock.length > 0) {
      const blockText = currentBlock.join('\n');
      result.push(
        <span key={`text-${result.length}`} className="whitespace-pre-wrap">
          {parseBoldGreenText(blockText, `text-${result.length}`)}
        </span>
      );
    }

    return result.length > 0 ? result : [<span key="empty" className="whitespace-pre-wrap">{parseBoldGreenText(content, 'empty')}</span>];
  };

  // Redirect to auth if not authenticated
  useEffect(() => {
    if (!isAuthenticated) {
      navigate('/auth');
    }
  }, [isAuthenticated, navigate]);

  // Auto scroll to bottom when new messages arrive
  useEffect(() => {
    if (scrollAreaRef.current) {
      scrollAreaRef.current.scrollTop = scrollAreaRef.current.scrollHeight;
    }
  }, [messages]);

  // Focus input on mount
  useEffect(() => {
    if (inputRef.current) {
      inputRef.current.focus();
    }
  }, []);

  // Check OpenAI API key on mount
  useEffect(() => {
    const checkApiKey = async () => {
      const apiKey = import.meta.env.VITE_OPENAI_API_KEY;
      if (!apiKey || apiKey === 'your_openai_api_key_here') {
        setApiKeyStatus('invalid');
        return;
      }

      // –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å API —á–µ—Ä–µ–∑ health endpoint —Å–µ—Ä–≤–µ—Ä–∞
      try {
        const response = await fetch(`${window.location.origin}/health`);
        if (response.ok) {
          // –ï—Å–ª–∏ —Å–µ—Ä–≤–µ—Ä –æ—Ç–≤–µ—á–∞–µ—Ç, —Å—á–∏—Ç–∞–µ–º —á—Ç–æ API –∫–ª—é—á –Ω–∞—Å—Ç—Ä–æ–µ–Ω
          // (—Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ —Å–µ—Ä–≤–µ—Ä–∞)
          setApiKeyStatus('valid');
        } else {
          setApiKeyStatus('error');
        }
      } catch (error) {
        console.error('API key check failed:', error);
        setApiKeyStatus('error');
      }
    };

    checkApiKey();
  }, []);

  // Initialize chat with welcome message for new learning sessions
  useEffect(() => {
    const urlParams = new URLSearchParams(window.location.search);
    const startParam = urlParams.get('start');
    const modeParam = urlParams.get('mode');

    if (startParam === 'true' && messages.length === 0) {
      // Check if this is adaptive assessment mode
      if (modeParam === 'adaptive') {
        setIsInAdaptiveMode(true);
        setAssessmentState('collecting_grade');
        
        const welcomeMessage: Message = {
          id: `welcome-${Date.now()}`,
          role: 'assistant',
          content: '–Ø –ø—Ä–æ–≤–µ–¥—É –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–Ω—Ç–µ—Ä–≤—å—é, —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å —Ç–≤–æ–π —É—Ä–æ–≤–µ–Ω—å –∏ —Å–æ—Å—Ç–∞–≤–∏—Ç—å –ø–ª–∞–Ω. –û—Ç–≤–µ—á–∞–π –∫–æ—Ä–æ—Ç–∫–æ. –í –∫–∞–∫–æ–º —Ç—ã –∫–ª–∞—Å—Å–µ —É—á–∏—à—å—Å—è?',
          timestamp: new Date(),
          ttsPlayed: false
        };
        
        setMessages([welcomeMessage]);
      } else {
        // Regular chat mode
        const welcomeContent = '–ü—Ä–∏–≤–µ—Ç! –Ø –≤–∞—à –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π AI-—É—á–∏—Ç–µ–ª—å. ' +
          '–Ø –≥–æ—Ç–æ–≤ –ø–æ–º–æ—á—å –≤–∞–º —Å –æ–±—É—á–µ–Ω–∏–µ–º –∏ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –ª—é–±—ã–µ –≤–æ–ø—Ä–æ—Å—ã!\n\n' +
          '–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞:\n1. –í –∫–∞–∫–æ–º –∫–ª–∞—Å—Å–µ –≤—ã —É—á–∏—Ç–µ—Å—å –∏–ª–∏ –≤ –∫–∞–∫–æ–º –≤—É–∑–µ?\n2. –ö–∞–∫–∏–µ —Ç–µ–º—ã –≤–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É—é—Ç?\n\n' +
          '–Ø –ø–æ–º–æ–≥—É –≤–∞–º —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è —Å –ª—é–±—ã–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏ –∏ –æ–±—ä—è—Å–Ω–∏—Ç—å —Å–ª–æ–∂–Ω—ã–µ —Ç–µ–º—ã –ø—Ä–æ—Å—Ç–æ –∏ –ø–æ–Ω—è—Ç–Ω–æ.';

        const welcomeMessage: Message = {
          id: `welcome-${Date.now()}`,
          role: 'assistant',
          content: welcomeContent,
          timestamp: new Date(),
          ttsPlayed: false
        };

        setMessages([welcomeMessage]);
      }
    }
  }, [messages.length]);

  // Format assessment results for display
  const formatAssessmentResults = (result: AssessmentResult): string => {
    let text = 'üìä **–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏**\n\n';
    text += `‚úÖ –ö–ª–∞—Å—Å: ${result.classGrade}\n`;
    text += `üìö –ü–æ—Å–ª–µ–¥–Ω—è—è —Ç–µ–º–∞: ${result.lastTopic || '–ù–∏—á–µ–≥–æ'}\n`;
    text += `üéØ –£—Ä–æ–≤–µ–Ω—å: ${result.cluster}\n\n`;

    text += '**–ú–∏–∫—Ä–æ-–ø—Ä–æ—Ñ–∏–ª—å –≤–ª–∞–¥–µ–Ω–∏—è:**\n';
    result.profile.forEach(p => {
      const level = p.p === 1.0 ? 'üü¢ –û—Ç–ª–∏—á–Ω–æ–µ' : p.p === 0.7 ? 'üü° –•–æ—Ä–æ—à–µ–µ' : p.p === 0.4 ? 'üü† –°—Ä–µ–¥–Ω–µ–µ' : 'üî¥ –°–ª–∞–±–æ–µ';
      text += `‚Ä¢ ${p.concept}: ${level} (${Math.round(p.p * 100)}%)\n`;
    });

    text += '\n**2-–Ω–µ–¥–µ–ª—å–Ω—ã–π –ø–ª–∞–Ω –æ–±—É—á–µ–Ω–∏—è:**\n';
    result.plan2w.forEach(session => {
      text += `\n**–°–µ—Å—Å–∏—è ${session.session}:**\n`;
      text += `üìã –¢–µ–º—ã: ${session.targets.join(', ')}\n`;
      text += `üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: –ü–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ ${Math.round(session.mix.review * 100)}% | –°–ª–∞–±—ã–µ ${Math.round(session.mix.weak * 100)}% | –ù–æ–≤–æ–µ ${Math.round(session.mix.new * 100)}%\n`;
    });

    text += '\nüöÄ –ì–æ—Ç–æ–≤—ã –Ω–∞—á–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ?';
    return text;
  };

  // Global keyboard shortcuts for TTS control
  useEffect(() => {
    const handleKeyDown = (event: KeyboardEvent) => {
      // Escape or Space to stop TTS
      if ((event.key === 'Escape' || event.key === ' ') && OpenAITTS.isPlaying()) {
        event.preventDefault();
        OpenAITTS.stop();
        console.log('üõë TTS stopped by keyboard shortcut');
      }
    };

    document.addEventListener('keydown', handleKeyDown);
    return () => document.removeEventListener('keydown', handleKeyDown);
  }, []);


  // Check if message contains audio task keywords
  const checkForAudioTask = (message: string): { isAudioTask: boolean; taskText: string } => {
    const audioTaskPatterns = [
      /–ø–æ–≤—Ç–æ—Ä–∏–º?\s+–≤—Å–µ/i,
      /–ø–æ–≤—Ç–æ—Ä–∏\s+–∑–∞\s+–º–Ω–æ–π/i,
      /–ø—Ä–æ–≥–æ–≤–æ—Ä–∏/i,
      /—Å–∫–∞–∂–∏\s+–ø–æ-–∞–Ω–≥–ª–∏–π—Å–∫–∏/i,
      /–ø—Ä–æ–∏–∑–Ω–µ—Å–∏/i,
      /–ø–æ–≤—Ç–æ—Ä–∏\s+—Ü–≤–µ—Ç–∞/i,
      /–ø–æ–≤—Ç–æ—Ä–∏\s+—á–∏—Å–ª–∞/i,
      /–¥–∞–≤–∞–π\s+–ø–æ–≤—Ç–æ—Ä–∏–º/i,
      /—Ç–µ–ø–µ—Ä—å\s+–ø–æ–≤—Ç–æ—Ä–∏–º/i,
      /–ø–æ–ø—Ä–æ–±—É–µ–º\s+—Å–Ω–æ–≤–∞/i
    ];

    const isAudioTask = audioTaskPatterns.some(pattern => pattern.test(message));
    let taskText = '';

    if (isAudioTask) {
      // Extract the specific task from the message
      if (message.includes('–ø–æ–≤—Ç–æ—Ä–∏')) {
        const match = message.match(/–ø–æ–≤—Ç–æ—Ä–∏[^\n]*/i);
        if (match) taskText = match[0];
      } else if (message.includes('–ø—Ä–æ–≥–æ–≤–æ—Ä–∏')) {
        const match = message.match(/–ø—Ä–æ–≥–æ–≤–æ—Ä–∏[^\n]*/i);
        if (match) taskText = match[0];
      } else if (message.includes('—Å–∫–∞–∂–∏')) {
        const match = message.match(/—Å–∫–∞–∂–∏[^\n]*/i);
        if (match) taskText = match[0];
      } else {
        taskText = '–í—ã–ø–æ–ª–Ω–∏ –∑–∞–¥–∞–Ω–∏–µ –≥–æ–ª–æ—Å–æ–º';
      }
    }

    return { isAudioTask, taskText };
  };

  // Check if message contains test question with options
  const checkForTestQuestion = (message: string): { isTestQuestion: boolean; questionData?: { question: string; options: string[]; currentQuestion: number; totalQuestions: number } } => {
    const testQuestionPattern = /–í–æ–ø—Ä–æ—Å\s+(\d+)\/(\d+):/i;
    const match = message.match(testQuestionPattern);

    if (!match) {
      return { isTestQuestion: false };
    }

    const currentQuestion = parseInt(match[1]);
    const totalQuestions = parseInt(match[2]);

    // First, check if this is from adaptive assessment and has structured options
    const lastMessage = messages[messages.length - 1];
    if (lastMessage && lastMessage.role === 'assistant' && currentAssessmentQuestion?.options) {
      return {
        isTestQuestion: true,
        questionData: {
          question: currentAssessmentQuestion.prompt,
          options: currentAssessmentQuestion.options,
          currentQuestion: currentQuestion,
          totalQuestions: totalQuestions
        }
      };
    }

    // Fallback: Look for options in parentheses like (in/on/under)
    const optionsMatch = message.match(/\(([^)]+)\)/);
    if (!optionsMatch) {
      return { isTestQuestion: false };
    }

    // Extract options
    const optionsText = optionsMatch[1];
    const options = optionsText.split('/').map(opt => opt.trim());

    // Extract the question text (everything before the options)
    const questionText = message.split('(')[0].trim();

    return {
      isTestQuestion: true,
      questionData: {
        question: questionText,
        options: options,
        currentQuestion: currentQuestion,
        totalQuestions: totalQuestions
      }
    };
  };

  // Handle audio task recording
  const startAudioTaskRecording = () => {
    if (!('webkitSpeechRecognition' in window && 'SpeechRecognition' in window)) {
      alert('–í–∞—à –±—Ä–∞—É–∑–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏');
      return;
    }

    const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.continuous = false;
    recognition.interimResults = false;
    recognition.lang = 'en-US'; // Listen for English speech
    recognitionRef.current = recognition;

    recognition.onstart = () => {
      setIsRecordingAudioTask(true);
    };

    recognition.onresult = (event: any) => {
      const transcript = event.results[0][0].transcript;
      console.log('Audio task transcript:', transcript);
      setInputMessage(transcript);
      setIsAudioTaskActive(false);
      setAudioTaskText('');
      setIsRecordingAudioTask(false);
      // Auto-send the message
      setTimeout(() => {
        sendMessage();
      }, 100);
    };

    recognition.onerror = (event: any) => {
      console.error('Speech recognition error:', event.error);
      setIsRecordingAudioTask(false);
      alert('–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.');
    };

    recognition.onend = () => {
      setIsRecordingAudioTask(false);
    };

    recognition.start();
  };

  // Handle test question answer selection
  const handleTestAnswer = async (selectedAnswer: string) => {
    console.log('üß™ handleTestAnswer called with:', selectedAnswer);
    console.log('üß™ isInAdaptiveMode:', isInAdaptiveMode);
    console.log('üß™ isTestQuestionActive:', isTestQuestionActive);

    // Directly resolve assessment promise if in adaptive mode
    if (isInAdaptiveMode && window._assessmentResolver) {
      console.log('üß™ Resolving adaptive assessment');
      window._assessmentResolver(selectedAnswer);
      setIsTestQuestionActive(false);
      setTestQuestionData(null);
      return;
    }

    // For test questions in regular chat, send directly
    console.log('üß™ Sending test answer directly');
    
    // Add user answer to chat
    const userMessage: Message = {
      id: Date.now().toString(),
      role: 'user',
      content: selectedAnswer,
      timestamp: new Date(),
    };

    // Hide test UI immediately
    setIsTestQuestionActive(false);
    setTestQuestionData(null);
    setIsLoading(true);

    // Add message and send to AI
    setMessages(prev => [...prev, userMessage]);
    
    // Send the answer to AI
    await sendDirectTestAnswer(selectedAnswer);
  };

  // Send test answer directly to AI
  const sendDirectTestAnswer = async (answer: string) => {
    try {
      const systemPrompt = `–í—ã - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ–¥–∞–≥–æ–≥ –∏ —ç–∫—Å–ø–µ—Ä—Ç –≤ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏. –í–∞—à–∞ –∑–∞–¥–∞—á–∞ - –æ–±—ä—è—Å–Ω—è—Ç—å –ª—é–±—ã–µ —Ç–µ–º—ã –±—ã—Å—Ç—Ä–æ, –ø–æ–Ω—è—Ç–Ω–æ –∏ –¥–æ—Å—Ç—É–ø–Ω–æ. –í—ã –º–æ–∂–µ—Ç–µ "—Ä–∞–∑–∂–µ–≤—ã–≤–∞—Ç—å" —Å–ª–æ–∂–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏, –ø—Ä–∏–≤–æ–¥–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã –∏–∑ —Ä–µ–∞–ª—å–Ω–æ–π –∂–∏–∑–Ω–∏, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–Ω–∞–ª–æ–≥–∏–∏ –∏ –ø–æ—à–∞–≥–æ–≤—ã–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è.

–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –≤–∞—à–µ–≥–æ —Å—Ç–∏–ª—è:
- –û–±—ä—è—Å–Ω—è–π—Ç–µ —Å–ª–æ–∂–Ω–æ–µ –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–∏–º–µ—Ä—ã –∏ –∞–Ω–∞–ª–æ–≥–∏–∏
- –†–∞–∑–±–∏–≤–∞–π—Ç–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –±–ª–æ–∫–∏
- –ó–∞–¥–∞–≤–∞–π—Ç–µ –Ω–∞–≤–æ–¥—è—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è
- –ë—É–¥—å—Ç–µ —Ç–µ—Ä–ø–µ–ª–∏–≤—ã –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏
- –ê–¥–∞–ø—Ç–∏—Ä—É–π—Ç–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –ø–æ–¥ —É—Ä–æ–≤–µ–Ω—å —É—á–µ–Ω–∏–∫–∞
- –ü–æ–æ—â—Ä—è–π—Ç–µ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ

–ö–†–ò–¢–ò–ß–ù–û –í–ê–ñ–ù–û: –ê–ö–¢–ò–í–ù–û –ò–°–ü–û–õ–¨–ó–£–ô–¢–ï –ò–°–¢–û–†–ò–Æ –ë–ï–°–ï–î–´!
- –í—Å–µ–≥–¥–∞ —Å—Å—ã–ª–∞–π—Ç–µ—Å—å –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
- –ü–æ–º–Ω–∏—Ç–µ, —á—Ç–æ –æ–±—Å—É–∂–¥–∞–ª–æ—Å—å —Ä–∞–Ω–µ–µ
- –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –ª–æ–≥–∏—á–µ—Å–∫—É—é –Ω–∏—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
- –ò–∑–±–µ–≥–∞–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π —É–∂–µ –æ–±—ä—è—Å–Ω–µ–Ω–Ω–æ–≥–æ
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ—Ä–∞–∑—ã —Ç–∏–ø–∞ "–∫–∞–∫ –º—ã –æ–±—Å—É–∂–¥–∞–ª–∏ —Ä–∞–Ω–µ–µ", "–ø—Ä–æ–¥–æ–ª–∂–∞—è –Ω–∞—à—É —Ç–µ–º—É", "–Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è"

–ö–û–ù–¢–ï–ö–°–¢ –û–ë–£–ß–ï–ù–ò–Ø: –£—á–µ–Ω–∏–∫ –≤—ã–±—Ä–∞–ª –∫—É—Ä—Å "–ê–Ω–≥–ª–∏–π—Å–∫–∏–π —è–∑—ã–∫". –í—ã –ø—Ä–µ–ø–æ–¥–∞–µ—Ç–µ –∏–º–µ–Ω–Ω–æ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º—É —è–∑—ã–∫—É. –í—Å–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –∏ –ø—Ä–∏–º–µ—Ä—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–≤—è–∑–∞–Ω—ã —Å —ç—Ç–∏–º –ø—Ä–µ–¥–º–µ—Ç–æ–º.`;

      const response = await fetch(`${window.location.origin}/api/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'gpt-4o-mini',
          messages: [
            {
              role: 'system',
              content: systemPrompt,
            },
            ...messages.slice(-29).map(msg => ({
              role: msg.role,
              content: msg.content,
            })),
            {
              role: 'user',
              content: answer
            }
          ],
          max_tokens: 2000,
          temperature: 0.7,
        }),
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}));
        console.error('OpenAI API Error:', {
          status: response.status,
          statusText: response.statusText,
          error: errorData
        });

        // Handle specific error codes
        if (response.status === 401) {
          throw new Error('–ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á OpenAI. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.');
        } else if (response.status === 429) {
          throw new Error('–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ OpenAI. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.');
        } else if (response.status === 500) {
          throw new Error('–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ OpenAI. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.');
        } else {
          throw new Error(`–û—à–∏–±–∫–∞ OpenAI: ${response.status} ${response.statusText}`);
        }
      }

      const data = await response.json();

      if (!data.choices || !data.choices[0] || !data.choices[0].message) {
        console.error('Invalid OpenAI response:', data);
        throw new Error('–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç OpenAI');
      }

      const aiContent = data.choices[0].message.content;

      const assistantMessage: Message = {
        id: Date.now().toString(),
        role: 'assistant',
        content: aiContent,
        timestamp: new Date(),
      };

      setMessages(prev => [...prev, assistantMessage]);
    } catch (error) {
      console.error('Error sending test answer:', error);
      const errorMessage: Message = {
        id: Date.now().toString(),
        role: 'assistant',
        content: '–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ—Ç–≤–µ—Ç–∞.',
        timestamp: new Date(),
      };
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
    }
  };

  const handleSkipTest = async () => {
    console.log('üß™ handleSkipTest called');

    // Directly resolve assessment promise if in adaptive mode
    if (isInAdaptiveMode && window._assessmentResolver) {
      console.log('üß™ Resolving skip in adaptive assessment');
      window._assessmentResolver('–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å');
      setIsTestQuestionActive(false);
      setTestQuestionData(null);
      return;
    }

    // For test questions in regular chat, send skip directly
    console.log('üß™ Sending skip action directly');
    
    const userMessage: Message = {
      id: Date.now().toString(),
      role: 'user',
      content: '–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å',
      timestamp: new Date(),
    };

    // Hide test UI immediately
    setIsTestQuestionActive(false);
    setTestQuestionData(null);
    setIsLoading(true);

    // Add message and send to AI
    setMessages(prev => [...prev, userMessage]);
    
    // Send the skip action to AI
    await sendDirectTestAnswer('–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å');
  };

  // Handle new assistant message to check for audio tasks and test questions
  useEffect(() => {
    const lastMessage = messages[messages.length - 1];
    if (lastMessage && lastMessage.role === 'assistant' && !lastMessage.ttsPlayed) {
      const { isAudioTask, taskText } = checkForAudioTask(lastMessage.content);
      if (isAudioTask) {
        setIsAudioTaskActive(true);
        setAudioTaskText(taskText || '–í—ã–ø–æ–ª–Ω–∏ –∑–∞–¥–∞–Ω–∏–µ –≥–æ–ª–æ—Å–æ–º');
      } else {
        const { isTestQuestion, questionData } = checkForTestQuestion(lastMessage.content);
        if (isTestQuestion && questionData) {
          // Convert text test question to interactive test
          console.log('üß™ Converting text test question to interactive test:', questionData);
          setIsTestQuestionActive(true);
          setTestQuestionData(questionData);

          // Mark message as processed to prevent re-processing
          lastMessage.ttsPlayed = true;
        }
      }
    }
  }, [messages]);

  // Function to handle lesson questions with context
  const sendLessonQuestion = async () => {
    if ((!inputMessage.trim() && uploadedFiles.length === 0) || isLoading || isProcessingFile) return;
    const currentLessonContext = lessonContextManager.getCurrentContext();
    if (!currentLessonContext) return;

    // Stop any ongoing TTS and sounds when user sends a new message
    if (OpenAITTS.isPlaying()) {
      OpenAITTS.stop();
      console.log('üõë TTS stopped due to new user message');
    }
    stopContinuousSound();

    let messageContent = inputMessage;
    const fileContents: string[] = [];

    // Process uploaded files first
    if (uploadedFiles.length > 0) {
      setIsProcessingFile(true);
      try {
        for (const file of uploadedFiles) {
          const extractedText = await processFile(file);
          fileContents.push(`\n\n--- –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ ${file.name} ---\n${extractedText}`);
        }
        messageContent += fileContents.join('\n');
      } catch (error) {
        console.error('Error processing files:', error);
        messageContent += '\n\n–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–æ–≤.';
      } finally {
        setIsProcessingFile(false);
      }
    }

    const userMessage: Message = {
      id: Date.now().toString(),
      role: 'user',
      content: messageContent,
      timestamp: new Date(),
    };

    setMessages(prev => [...prev, userMessage]);
    setInputMessage('');
    setUploadedFiles([]); // Clear uploaded files after sending
    setIsLoading(true);

    // Get lesson-aware system prompt from context manager
    const lessonSystemPrompt = lessonContextManager.getSystemPrompt();
    if (!lessonSystemPrompt) {
      console.error('No lesson system prompt available');
      return;
    }

    try {
      const response = await fetch(`${window.location.origin}/api/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'gpt-4o-mini',
          messages: [
            {
              role: 'system',
              content: lessonSystemPrompt,
            },
            ...messages.slice(-25).map(msg => ({
              role: msg.role,
              content: msg.content,
            })),
            {
              role: 'user',
              content: userMessage.content,
            },
          ],
          max_tokens: 1500,
          temperature: 0.7,
        }),
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}));
        console.error('OpenAI API Error:', {
          status: response.status,
          statusText: response.statusText,
          error: errorData
        });

        // Handle specific error codes
        if (response.status === 401) {
          throw new Error('–ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á OpenAI. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.');
        } else if (response.status === 429) {
          throw new Error('–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ OpenAI. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.');
        } else if (response.status === 500) {
          throw new Error('–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ OpenAI. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.');
        } else {
          throw new Error(`–û—à–∏–±–∫–∞ OpenAI: ${response.status} ${response.statusText}`);
        }
      }

      const data = await response.json();

      if (!data.choices || !data.choices[0] || !data.choices[0].message) {
        console.error('Invalid OpenAI response:', data);
        throw new Error('–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç OpenAI');
      }

      const aiContent = data.choices[0].message.content;

      const assistantMessage: Message = {
        id: (Date.now() + 1).toString(),
        role: 'assistant',
        content: aiContent,
        timestamp: new Date(),
      };

      setMessages(prev => [...prev, assistantMessage]);
    } catch (error) {
      console.error('Error sending lesson question:', error);
      const errorMessage: Message = {
        id: (Date.now() + 1).toString(),
        role: 'assistant',
        content: '–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –ø—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ —É—Ä–æ–∫.',
        timestamp: new Date(),
      };
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
      // Focus back to input after response
      setTimeout(() => {
        if (inputRef.current) {
          inputRef.current.focus();
        }
      }, 100);
    }
  };

  const sendMessage = async () => {
    if ((!inputMessage.trim() && uploadedFiles.length === 0) || isLoading || isProcessingFile) return;

    // Stop any ongoing TTS and sounds when user sends a new message
    if (OpenAITTS.isPlaying()) {
      OpenAITTS.stop();
      console.log('üõë TTS stopped due to new user message');
    }
    stopContinuousSound();

    let messageContent = inputMessage;
    const fileContents: string[] = [];

    // Process uploaded files first
    if (uploadedFiles.length > 0) {
      setIsProcessingFile(true);
      try {
        for (const file of uploadedFiles) {
          const extractedText = await processFile(file);
          fileContents.push(`\n\n--- –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ ${file.name} ---\n${extractedText}`);
        }
        messageContent += fileContents.join('\n');
      } catch (error) {
        console.error('Error processing files:', error);
        messageContent += '\n\n–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–æ–≤.';
      } finally {
        setIsProcessingFile(false);
      }
    }

    const userMessage: Message = {
      id: Date.now().toString(),
      role: 'user',
      content: messageContent,
      timestamp: new Date(),
    };

    setMessages(prev => [...prev, userMessage]);
    setInputMessage('');
    setUploadedFiles([]); // Clear uploaded files after sending
    setIsLoading(true);

    // Handle adaptive assessment mode
    if (isInAdaptiveMode) {
      if (assessmentState === 'collecting_grade') {
        setClassGrade(messageContent);
        setAssessmentState('collecting_topic');
        const topicQuestion: Message = {
          id: (Date.now() + 1).toString(),
          role: 'assistant',
          content: '–ß—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º –ø—Ä–æ—Ö–æ–¥–∏–ª(–∞) –ø–æ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º—É?',
          timestamp: new Date(),
        };
        setMessages(prev => [...prev, topicQuestion]);
        setIsLoading(false);
        return;
      } else if (assessmentState === 'collecting_topic') {
        setLastTopic(messageContent);
        setAssessmentState('in_progress');
        setQuestionCount(0);
        
        // Start adaptive assessment - this will run in background
        runAdaptiveAssessment(
          classGrade,
          messageContent,
          async (question: AssessmentQuestion, num: number, total: number) => {
            // Show question
            let questionContent = `–í–æ–ø—Ä–æ—Å ${num}/${total}:\n\n${question.prompt}`;

            // Add options if available
            if (question.options && question.options.length > 0) {
              questionContent += ` (${question.options.join('/')})`;
            }

            const questionMsg: Message = {
              id: (Date.now() + num).toString(),
              role: 'assistant',
              content: questionContent,
              timestamp: new Date(),
            };
            setMessages(prev => [...prev, questionMsg]);
            setCurrentAssessmentQuestion(question);
            setQuestionCount(num);
            setIsLoading(false); // Reset loading indicator after showing question

            // Wait for user input
            return new Promise<string>((resolve) => {
              // This will be resolved when user sends next message
              const resolver = (ans: string) => {
                resolve(ans);
                window._assessmentResolver = null;
              };
              window._assessmentResolver = resolver;
            });
          },
          (progress) => {
            console.log('Assessment progress:', progress);
          }
        ).then(async (result) => {
          // Assessment completed successfully
          console.log('üéâ Assessment completed:', result);
          setAssessmentResult(result);
          setAssessmentState('completed');

          // Save assessment to database
          try {
            // Validate CEFR level format
            const cefrLevels = ['A1', 'A2', 'B1', 'B2', 'C1', 'C2'];
            let cefrLevel = result.cluster || 'B1'; // Default to B1 if not provided

            // Ensure cefr_level is valid
            if (!cefrLevels.includes(cefrLevel)) {
              console.warn('‚ö†Ô∏è Invalid CEFR level:', cefrLevel, 'defaulting to B1');
              cefrLevel = 'B1';
            }

            // Calculate correct answers more accurately
            const totalQuestions = result.profile.length;
            const correctAnswers = Math.round(result.profile.reduce((sum, p) => sum + p.p, 0) / result.profile.length * totalQuestions);

            // Use a reasonable default duration since we don't track start time
            const durationSeconds = 300; // 5 minutes default

            const assessmentData = {
              user_id: 1,
              assessment_type: 'adaptive',
              cefr_level: cefrLevel,
              total_questions: totalQuestions,
              correct_answers: correctAnswers,
              duration_seconds: durationSeconds
            };

            console.log('üíæ Saving assessment:', assessmentData);
            console.log('üíæ Assessment data types:', {
              user_id: typeof assessmentData.user_id,
              assessment_type: typeof assessmentData.assessment_type,
              cefr_level: typeof assessmentData.cefr_level,
              total_questions: typeof assessmentData.total_questions,
              correct_answers: typeof assessmentData.correct_answers,
              duration_seconds: typeof assessmentData.duration_seconds
            });

            // Ensure all numeric fields are actually numbers
            const sanitizedData = {
              user_id: Number(assessmentData.user_id),
              assessment_type: String(assessmentData.assessment_type),
              cefr_level: assessmentData.cefr_level ? String(assessmentData.cefr_level) : null,
              total_questions: Number(assessmentData.total_questions),
              correct_answers: Number(assessmentData.correct_answers),
              duration_seconds: Number(assessmentData.duration_seconds)
            };

            console.log('üßπ Sanitized data:', sanitizedData);

            const response = await fetch('/api/db/assessments', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify(sanitizedData)
            });

            if (response.ok) {
              const dbResult = await response.json();
              console.log('‚úÖ Assessment saved to database:', dbResult);
            } else {
              const errorData = await response.json().catch(() => ({ message: 'Unknown error' }));
              console.error('‚ùå Failed to save assessment to database:', {
                status: response.status,
                statusText: response.statusText,
                error: errorData
              });
            }
          } catch (dbError) {
            console.warn('‚ö†Ô∏è Database save error:', dbError);
          }

          // Show results
          const resultsMsg: Message = {
            id: (Date.now() + 1000).toString(),
            role: 'assistant',
            content: formatAssessmentResults(result),
            timestamp: new Date(),
          };
          setMessages(prev => [...prev, resultsMsg]);
          setIsLoading(false);
        }).catch((error) => {
          console.error('Assessment error:', error);
          const errorMsg: Message = {
            id: (Date.now() + 999).toString(),
            role: 'assistant',
            content: '–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–∏ –∏–Ω—Ç–µ—Ä–≤—å—é. –ü–æ–ø—Ä–æ–±—É–µ–º –µ—â–µ —Ä–∞–∑.',
            timestamp: new Date(),
          };
          setMessages(prev => [...prev, errorMsg]);
          setAssessmentState('initial');
          setIsLoading(false);
        });
        return;
      } else if (assessmentState === 'in_progress' && currentAssessmentQuestion) {
        // User answered the question - resolve the promise
        // Do not clear currentAssessmentQuestion or reset questionCount
        if (window._assessmentResolver) {
          window._assessmentResolver(messageContent);
        }
        // Return to allow adaptive loop to progress to the next question
        return;
      }
    }

    // –°–æ–∑–¥–∞—Ç—å –±–∞–∑–æ–≤—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —á–∞—Ç–∞
    const systemPrompt = `–í—ã - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ–¥–∞–≥–æ–≥ –∏ —ç–∫—Å–ø–µ—Ä—Ç –≤ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏. –í–∞—à–∞ –∑–∞–¥–∞—á–∞ - –æ–±—ä—è—Å–Ω—è—Ç—å –ª—é–±—ã–µ —Ç–µ–º—ã –±—ã—Å—Ç—Ä–æ, –ø–æ–Ω—è—Ç–Ω–æ –∏ –¥–æ—Å—Ç—É–ø–Ω–æ. –í—ã –º–æ–∂–µ—Ç–µ "—Ä–∞–∑–∂–µ–≤—ã–≤–∞—Ç—å" —Å–ª–æ–∂–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏, –ø—Ä–∏–≤–æ–¥–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã –∏–∑ —Ä–µ–∞–ª—å–Ω–æ–π –∂–∏–∑–Ω–∏, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–Ω–∞–ª–æ–≥–∏–∏ –∏ –ø–æ—à–∞–≥–æ–≤—ã–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è.

–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –≤–∞—à–µ–≥–æ —Å—Ç–∏–ª—è:
- –û–±—ä—è—Å–Ω—è–π—Ç–µ —Å–ª–æ–∂–Ω–æ–µ –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–∏–º–µ—Ä—ã –∏ –∞–Ω–∞–ª–æ–≥–∏–∏
- –†–∞–∑–±–∏–≤–∞–π—Ç–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –±–ª–æ–∫–∏
- –ó–∞–¥–∞–≤–∞–π—Ç–µ –Ω–∞–≤–æ–¥—è—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è
- –ë—É–¥—å—Ç–µ —Ç–µ—Ä–ø–µ–ª–∏–≤—ã –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏
- –ê–¥–∞–ø—Ç–∏—Ä—É–π—Ç–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –ø–æ–¥ —É—Ä–æ–≤–µ–Ω—å —É—á–µ–Ω–∏–∫–∞
- –ü–æ–æ—â—Ä—è–π—Ç–µ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ

–ö–†–ò–¢–ò–ß–ù–û –í–ê–ñ–ù–û: –ê–ö–¢–ò–í–ù–û –ò–°–ü–û–õ–¨–ó–£–ô–¢–ï –ò–°–¢–û–†–ò–Æ –ë–ï–°–ï–î–´!
- –í—Å–µ–≥–¥–∞ —Å—Å—ã–ª–∞–π—Ç–µ—Å—å –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
- –ü–æ–º–Ω–∏—Ç–µ, —á—Ç–æ –æ–±—Å—É–∂–¥–∞–ª–æ—Å—å —Ä–∞–Ω–µ–µ
- –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –ª–æ–≥–∏—á–µ—Å–∫—É—é –Ω–∏—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
- –ò–∑–±–µ–≥–∞–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π —É–∂–µ –æ–±—ä—è—Å–Ω–µ–Ω–Ω–æ–≥–æ
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ—Ä–∞–∑—ã —Ç–∏–ø–∞ "–∫–∞–∫ –º—ã –æ–±—Å—É–∂–¥–∞–ª–∏ —Ä–∞–Ω–µ–µ", "–ø—Ä–æ–¥–æ–ª–∂–∞—è –Ω–∞—à—É —Ç–µ–º—É", "–Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è"`;

    try {
      const response = await fetch(`${window.location.origin}/api/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'gpt-4o-mini',
          messages: [
            {
              role: 'system',
              content: systemPrompt,
            },
            ...messages.slice(-29).map(msg => ({
              role: msg.role,
              content: msg.content,
            })),
            {
              role: 'user',
              content: userMessage.content,
            },
          ],
          max_tokens: 2000,
          temperature: 0.7,
        }),
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}));
        console.error('OpenAI API Error:', {
          status: response.status,
          statusText: response.statusText,
          error: errorData
        });

        // Handle specific error codes
        if (response.status === 401) {
          throw new Error('–ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á OpenAI. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.');
        } else if (response.status === 429) {
          throw new Error('–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ OpenAI. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.');
        } else if (response.status === 500) {
          throw new Error('–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ OpenAI. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.');
        } else {
          throw new Error(`–û—à–∏–±–∫–∞ OpenAI: ${response.status} ${response.statusText}`);
        }
      }

      const data = await response.json();

      if (!data.choices || !data.choices[0] || !data.choices[0].message) {
        console.error('Invalid OpenAI response:', data);
        throw new Error('–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç OpenAI');
      }

      const aiContent = data.choices[0].message.content;
      
      const assistantMessage: Message = {
        id: (Date.now() + 1).toString(),
        role: 'assistant',
        content: aiContent,
        timestamp: new Date(),
      };

      setMessages(prev => [...prev, assistantMessage]);
    } catch (error) {
      console.error('Error sending message:', error);
      const errorMessage: Message = {
        id: (Date.now() + 1).toString(),
        role: 'assistant',
        content: '–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.',
        timestamp: new Date(),
      };
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
      // Focus back to input after response
      setTimeout(() => {
        if (inputRef.current) {
          inputRef.current.focus();
        }
      }, 100);
    }
  };

  // Functions for lesson mode management
  const startLessonMode = (lessonData: {
    lessonId: string;
    currentTopic: string;
    lessonProgress?: string;
  }) => {
    lessonContextManager.startLesson(lessonData);
    setIsLessonMode(true);
    console.log('üìö Lesson mode activated:', lessonData);
  };

  const updateLessonBlock = (block: LessonBlock, blockIndex?: number, totalBlocks?: number) => {
    lessonContextManager.updateCurrentBlock(block, blockIndex, totalBlocks);
    console.log('üìñ Lesson block updated:', block.title);
  };

  const endLessonMode = () => {
    lessonContextManager.endLesson();
    setIsLessonMode(false);
    console.log('üìö Lesson mode deactivated');
  };

  const handleKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      if (isLessonMode && lessonContextManager.getCurrentContext()) {
        sendLessonQuestion();
      } else {
        sendMessage();
      }
    }
  };

  if (!isAuthenticated) {
    return null; // Will redirect to auth
  }


  // Animated Sphere Component
  const AnimatedSphere = () => (
    <div className="min-h-screen bg-gradient-to-br from-background via-secondary/30 to-background flex items-center justify-center">
      <div className="relative">
        {/* Main sphere */}
        <div className="w-32 h-32 bg-gradient-to-r from-blue-500 to-purple-600 rounded-full animate-pulse shadow-2xl relative overflow-hidden">
          <div className="absolute inset-0 bg-gradient-to-r from-transparent via-white/20 to-transparent animate-pulse"></div>
          <div className="absolute inset-2 bg-gradient-to-r from-purple-600 to-blue-500 rounded-full opacity-80 animate-ping"></div>
          <div className="absolute inset-4 bg-gradient-to-r from-blue-500 to-purple-600 rounded-full opacity-60 animate-bounce"></div>
        </div>

        {/* Orbiting elements */}
        <div className="absolute inset-0 animate-spin" style={{ animationDuration: '3s' }}>
          <div className="w-2 h-2 bg-yellow-400 rounded-full absolute top-0 left-1/2 transform -translate-x-1/2 -translate-y-1"></div>
          <div className="w-2 h-2 bg-green-400 rounded-full absolute bottom-0 left-1/2 transform -translate-x-1/2 translate-y-1"></div>
        </div>

        {/* Calm orbiting elements */}
        <div className="absolute inset-0" style={{
          animation: 'gentle-orbit 8s linear infinite'
        }}>
          <div className="w-2 h-2 bg-gradient-to-br from-blue-300 to-blue-400 rounded-full absolute opacity-70 shadow-lg"
               style={{
                 left: '50%',
                 top: '50%',
                 transform: 'translate(-50%, -50%) translateX(-80px)',
                 animation: 'float-glow 4s ease-in-out infinite alternate'
               }}>
          </div>
        </div>

        <div className="absolute inset-0" style={{
          animation: 'gentle-orbit 8s linear infinite reverse'
        }}>
          <div className="w-1.8 h-1.8 bg-gradient-to-br from-purple-300 to-pink-300 rounded-full absolute opacity-60 shadow-lg"
               style={{
                 left: '50%',
                 top: '50%',
                 transform: 'translate(-50%, -50%) translateX(75px)',
                 animation: 'float-glow 3.5s ease-in-out infinite alternate reverse'
               }}>
          </div>
        </div>

        {/* Back to chat button */}
        <Button
          onClick={() => setShowSphere(false)}
          className="absolute -bottom-16 left-1/2 transform -translate-x-1/2 mt-4"
          variant="outline"
        >
          <ArrowLeft className="w-4 h-4 mr-2" />
          –í–µ—Ä–Ω—É—Ç—å—Å—è –∫ —á–∞—Ç—É
        </Button>
      </div>
    </div>
  );

  if (showSphere) {
    return (
      <div className="min-h-screen bg-gradient-to-br from-background via-secondary/30 to-background flex items-center justify-center">
        <AnimatedSphere />
      </div>
    );
  }

  return (
    <div className="min-h-screen bg-gradient-to-br from-background via-secondary/30 to-background">

      {/* Header */}
      <header className="border-b border-border/50 bg-card/50 backdrop-blur-sm">
        <div className="container mx-auto px-4 py-4">
          <div className="flex items-center justify-between gap-2">
            {/* Left side - Logo */}
            <div className="flex items-center gap-2 flex-shrink-0">
              <div className="w-8 h-8 bg-gradient-to-r from-primary to-accent rounded-xl flex items-center justify-center">
                <Brain className="w-4 h-4 text-white" />
              </div>
              <h1 className="text-sm sm:text-lg font-semibold hidden sm:block">Windexs-–£—á–∏—Ç–µ–ª—å</h1>
            </div>

            {/* Right side - Title */}
            <div className="flex items-center gap-2 flex-shrink-0">
              <MessageCircle className="w-5 h-5 text-primary" />
              <h2 className="text-sm sm:text-lg font-medium hidden sm:block">AI –£—á–∏—Ç–µ–ª—å</h2>
            </div>
          </div>
        </div>
      </header>

      {/* Chat Container */}
      <div className="container mx-auto px-4 py-6 max-w-4xl">
        <Card className="h-[calc(100vh-12rem)]">
          <CardHeader className="pb-4">
            <CardTitle className="flex items-center gap-2">
              <Brain className="w-5 h-5 text-primary" />
              –ß–∞—Ç —Å AI –£—á–∏—Ç–µ–ª–µ–º
              {isLessonMode && lessonContextManager.getCurrentContext() && (
                <span className="ml-2 px-2 py-1 bg-blue-100 dark:bg-blue-900 text-blue-800 dark:text-blue-200 text-xs rounded-full font-medium">
                  üìö –£—Ä–æ–∫: {lessonContextManager.getCurrentContext()?.currentTopic}
                </span>
              )}
            </CardTitle>
            <p className="text-sm text-muted-foreground">
              {isLessonMode && lessonContextManager.getCurrentContext() ? (
                <span className="text-blue-600 font-medium">
                  üí¨ –í–æ –≤—Ä–µ–º—è —É—Ä–æ–∫–∞ –≤—ã –º–æ–∂–µ—Ç–µ –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –ø–æ —Ç–µ–º–µ "{lessonContextManager.getCurrentContext()?.currentTopic}".
                  –£—á–∏—Ç–µ–ª—å –±—É–¥–µ—Ç –æ—Ç–≤–µ—á–∞—Ç—å, —É—á–∏—Ç—ã–≤–∞—è –∫–æ–Ω—Ç–µ–∫—Å—Ç —É—Ä–æ–∫–∞.
                </span>
              ) : (
                <span>üí¨ –ó–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –ª—é–±—ã–º —Ç–µ–º–∞–º. AI –£—á–∏—Ç–µ–ª—å –ø–æ–º–æ–∂–µ—Ç –≤–∞–º —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è!</span>
              )}
              {apiKeyStatus === 'invalid' && (
                <span className="text-red-600 font-medium block mt-1">
                  ‚ùå OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω! –î–æ–±–∞–≤—å—Ç–µ VITE_OPENAI_API_KEY –≤ —Ñ–∞–π–ª .env
                </span>
              )}
              {apiKeyStatus === 'error' && (
                <span className="text-orange-600 font-medium block mt-1">
                  ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å API –∫–ª—é—á. –í–æ–∑–º–æ–∂–Ω–æ, –ø—Ä–æ–±–ª–µ–º—ã —Å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–æ–º.
                </span>
              )}
            </p>
          </CardHeader>

          <CardContent className="flex flex-col h-full">
            {/* Messages Area */}
            <ScrollArea className="flex-1 pr-4 mb-4" ref={scrollAreaRef}>
              <div className="space-y-4">
                {messages.length === 0 && (
                  <div className="text-center py-8 text-muted-foreground">
                    <Brain className="w-12 h-12 mx-auto mb-4 text-primary/50" />
                    <p className="text-lg mb-2">–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ —á–∞—Ç —Å AI –£—á–∏—Ç–µ–ª–µ–º!</p>
                    <p>–ó–∞–¥–∞–π—Ç–µ —Å–≤–æ–π –ø–µ—Ä–≤—ã–π –≤–æ–ø—Ä–æ—Å, –∏ —è –ø–æ–º–æ–≥—É —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è –≤ –ª—é–±–æ–π —Ç–µ–º–µ.</p>
                    <div className="mt-4 space-y-2 text-sm">
                      <p><strong>–ü—Ä–∏–º–µ—Ä—ã –≤–æ–ø—Ä–æ—Å–æ–≤:</strong></p>
                      <div className="space-y-1 text-left max-w-md mx-auto">
                        <p>‚Ä¢ "–û–±—ä—è—Å–Ω–∏, —á—Ç–æ —Ç–∞–∫–æ–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è"</p>
                        <p>‚Ä¢ "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ñ–æ—Ç–æ—Å–∏–Ω—Ç–µ–∑?"</p>
                        <p>‚Ä¢ "–†–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ –≤—Ç–æ—Ä—É—é –º–∏—Ä–æ–≤—É—é –≤–æ–π–Ω—É"</p>
                      </div>
                    </div>
                  </div>
                )}

                {messages.map((message) => (
                  <div
                    key={message.id}
                    className={`flex gap-3 ${message.role === 'user' ? 'justify-end' : 'justify-start'}`}
                  >
                    {message.role === 'assistant' && (
                      <Avatar className="w-8 h-8">
                        <AvatarFallback className="bg-primary/10 text-primary">
                          <Brain className="w-4 h-4" />
                        </AvatarFallback>
                      </Avatar>
                    )}

                    {/* Regular Message Bubble */}
                    <div
                      className={`max-w-[70%] rounded-lg px-4 py-2 ${
                        message.role === 'user'
                          ? 'bg-primary text-primary-foreground'
                          : 'bg-muted'
                      }`}
                    >
                      <div className="whitespace-pre-wrap">
                        {formatMessageContent(message.content)}
                      </div>
                      <div className="flex items-center justify-between mt-2">
                        <p className="text-xs opacity-70">
                          {message.timestamp.toLocaleTimeString()}
                        </p>
                        {/* TTS Button - only for assistant messages and when auto-TTS is disabled */}
                        {message.role === 'assistant' && isTTSAvailable() && !isTtsEnabled && (
                          <Button
                            variant="ghost"
                            size="sm"
                            onClick={() => {
                              if (!OpenAITTS.isPlaying()) {
                                speakTextBySentences(message.content, message.id);
                              }
                            }}
                            className={`h-6 w-6 p-0 ${
                              speakingMessageId === message.id
                                ? 'text-red-500 hover:text-red-600'
                                : 'text-muted-foreground hover:text-foreground'
                            }`}
                            title={speakingMessageId === message.id ? '–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ–∑–≤—É—á–∏–≤–∞–Ω–∏–µ' : '–û–∑–≤—É—á–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ'}
                          >
                            {speakingMessageId === message.id ? (
                              <VolumeX className="h-3 w-3" />
                            ) : (
                              <Volume2 className="h-3 w-3" />
                            )}
                          </Button>
                        )}

                        {/* Auto-TTS indicator - show when auto-TTS is enabled */}
                        {message.role === 'assistant' && isTtsEnabled && (
                          <div className="flex items-center text-green-600" title="–ê–≤—Ç–æ-–æ–∑–≤—É—á–∏–≤–∞–Ω–∏–µ –≤–∫–ª—é—á–µ–Ω–æ">
                            <Volume2 className="h-3 w-3" />
                          </div>
                        )}
                      </div>
                    </div>

                    {message.role === 'user' && (
                      <Avatar className="w-8 h-8">
                        <AvatarFallback className="bg-accent text-accent-foreground">
                          <User className="w-4 h-4" />
                        </AvatarFallback>
                      </Avatar>
                    )}
                  </div>
                ))}

                {isLoading && (
                  <div className="flex gap-3 justify-start">
                    <Avatar className="w-8 h-8">
                      <AvatarFallback className="bg-primary/10 text-primary">
                        <Brain className="w-4 h-4" />
                      </AvatarFallback>
                    </Avatar>
                    <div className="bg-muted rounded-lg px-4 py-2">
                      <div className="flex items-center gap-2">
                        <div className="flex gap-1">
                          <div className="w-2 h-2 bg-primary/50 rounded-full animate-bounce" />
                          <div className="w-2 h-2 bg-primary/50 rounded-full animate-bounce" style={{ animationDelay: '0.1s' }} />
                          <div className="w-2 h-2 bg-primary/50 rounded-full animate-bounce" style={{ animationDelay: '0.2s' }} />
                        </div>
                        <span className="text-sm text-muted-foreground">–£—á–∏—Ç–µ–ª—å –¥—É–º–∞–µ—Ç...</span>
                      </div>
                    </div>
                  </div>
                )}
              </div>
            </ScrollArea>

            {/* Camera Interface */}
            {isCameraActive && (
              <div className="mb-4 p-4 border rounded-lg bg-muted/30">
                <div className="relative">
                  <video
                    ref={videoRef}
                    autoPlay
                    playsInline
                    muted
                    className="w-full max-h-64 bg-black rounded"
                  />
                  <canvas ref={canvasRef} className="hidden" />
                  <div className="absolute bottom-2 left-1/2 transform -translate-x-1/2 flex gap-2">
                    <Button
                      size="sm"
                      onClick={capturePhoto}
                      className="bg-primary hover:bg-primary/90"
                    >
                      üì∏ –°—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä–æ–≤–∞—Ç—å
                    </Button>
                    <Button
                      size="sm"
                      variant="outline"
                      onClick={stopCamera}
                      className="bg-black/50 text-white border-white/30 hover:bg-black/70"
                    >
                      ‚ùå –û—Ç–º–µ–Ω–∞
                    </Button>
                  </div>
                </div>
              </div>
            )}

            {/* Captured Image Preview */}
            {capturedImage && (
              <div className="mb-4 p-4 border rounded-lg bg-muted/30">
                <div className="text-center">
                  <img
                    src={capturedImage}
                    alt="–°—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∑–∞–¥–∞—á–∞"
                    className="max-h-64 mx-auto rounded"
                  />
                  <div className="mt-3 flex gap-2 justify-center">
                    <Button
                      size="sm"
                      onClick={sendCapturedPhoto}
                      disabled={isLoading}
                    >
                      {isLoading ? "–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é..." : "üß† –†–µ—à–∏—Ç—å –∑–∞–¥–∞—á—É"}
                    </Button>
                    <Button
                      size="sm"
                      variant="outline"
                      onClick={retakePhoto}
                      disabled={isLoading}
                    >
                      üîÑ –ü–µ—Ä–µ—Å–Ω—è—Ç—å
                    </Button>
                  </div>
                </div>
              </div>
            )}

            {/* Voice Chat Status */}
            {isVoiceChatActive && (
              <div className="px-4 py-2 border-t bg-blue-50 dark:bg-blue-950/20">
                <div className="flex items-center gap-2 text-sm text-blue-700 dark:text-blue-300">
                  {isListening ? (
                    <>
                      <Mic className="w-4 h-4 animate-pulse text-green-600" />
                      <span>üé§ –°–ª—É—à–∞—é - –≥–æ–≤–æ—Ä–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å...</span>
                    </>
                  ) : isGeneratingTTS ? (
                    <>
                      <Brain className="w-4 h-4 animate-pulse text-purple-600" />
                      <span>üéµ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ—Ç–≤–µ—Ç–∞...</span>
                    </>
                  ) : OpenAITTS.isPlaying() ? (
                    <>
                      <Volume2 className="w-4 h-4 animate-pulse text-blue-600" />
                      <span>üîä –û—Ç–≤–µ—á–∞—é –≥–æ–ª–æ—Å–æ–º...</span>
                    </>
                  ) : (
                    <>
                      <Brain className="w-4 h-4 animate-pulse text-orange-600" />
                      <span>ü§î –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –æ—Ç–≤–µ—Ç...</span>
                    </>
                  )}
                </div>
                {ttsInterrupted && (
                  <div className="mt-2 flex items-center gap-2 text-sm text-red-600 dark:text-red-400">
                    <span>‚ö° TTS –ø—Ä–µ—Ä–≤–∞–Ω —Ä–µ—á—å—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è</span>
                  </div>
                )}
              </div>
            )}

            {/* Uploaded Files Display */}
            {uploadedFiles.length > 0 && (
              <div className="px-4 py-2 border-t bg-muted/30">
                <div className="flex flex-wrap gap-2">
                  {uploadedFiles.map((file, index) => (
                    <div
                      key={index}
                      className="flex items-center gap-2 bg-background rounded-lg px-3 py-2 border text-sm"
                    >
                      {getFileIcon(file)}
                      <span className="truncate max-w-32">{file.name}</span>
                      <Button
                        variant="ghost"
                        size="sm"
                        onClick={() => removeFile(index)}
                        className="h-4 w-4 p-0 hover:bg-destructive/20"
                      >
                        <X className="w-3 h-3" />
                      </Button>
                    </div>
                  ))}
                </div>
              </div>
            )}

            {/* Input Area */}
            <div className="flex flex-wrap gap-2 pt-4 border-t">
              <input
                ref={fileInputRef}
                type="file"
                accept="image/*,.pdf,.doc,.docx"
                multiple
                onChange={handleFileUpload}
                className="hidden"
              />
              <Button
                variant="outline"
                size="icon"
                onClick={() => fileInputRef.current?.click()}
                disabled={isLoading}
                title="–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, PDF, DOCX)"
              >
                <Upload className="w-4 h-4" />
              </Button>

              {/* Camera Button */}
              <Button
                variant={isCameraActive ? "destructive" : "outline"}
                size="icon"
                onClick={isCameraActive ? stopCamera : startCamera}
                disabled={isLoading}
                title={isCameraActive ? "–ó–∞–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É" : "–°—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä–æ–≤–∞—Ç—å –∑–∞–¥–∞—á—É"}
                className={isCameraActive ? "animate-pulse" : ""}
              >
                <Camera className="w-4 h-4" />
              </Button>

                  {/* Test Question UI */}
                  {isTestQuestionActive && testQuestionData ? (
                    <div className="w-full max-w-xl bg-gradient-to-r from-emerald-50 to-green-50 border-2 border-emerald-200 rounded-lg p-4 shadow-sm">
                      <div className="space-y-3">
                        <div className="flex items-center gap-3">
                          <div className="w-8 h-8 bg-emerald-100 rounded-full flex items-center justify-center flex-shrink-0">
                            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round" className="lucide lucide-brain w-4 h-4 text-emerald-600">
                              <path d="M12 5a3 3 0 1 0-5.997.125 4 4 0 0 0-2.526 5.77 4 4 0 0 0 .556 6.588A4 4 0 1 0 12 18Z"></path>
                              <path d="M12 5a3 3 0 1 1 5.997.125 4 4 0 0 1 2.526 5.77 4 4 0 0 1-.556 6.588A4 4 0 1 1 12 18Z"></path>
                              <path d="M15 13a4.5 4.5 0 0 1-3-4 4.5 4.5 0 0 1-3 4"></path>
                              <path d="M17.599 6.5a3 3 0 0 0 .399-1.375"></path>
                              <path d="M6.003 5.125A3 3 0 0 0 6.401 6.5"></path>
                              <path d="M3.477 10.896a4 4 0 0 1 .585-.396"></path>
                              <path d="M19.938 10.5a4 4 0 0 1 .585.396"></path>
                              <path d="M6 18a4 4 0 0 1-1.967-.516"></path>
                              <path d="M19.967 17.484A4 4 0 0 1 18 18"></path>
                            </svg>
                          </div>
                          <div className="min-w-0">
                            <p className="font-semibold text-emerald-900 text-sm">üìö –¢–µ—Å—Ç–æ–≤–æ–µ –∑–∞–¥–∞–Ω–∏–µ</p>
                            <p className="text-xs text-emerald-700">
                              –í–æ–ø—Ä–æ—Å {testQuestionData.currentQuestion}/{testQuestionData.totalQuestions}
                            </p>
                          </div>
                        </div>
                        <div className="bg-white rounded-lg p-3 border border-emerald-200">
                          <p className="text-base font-medium text-gray-800 mb-3">
                            {testQuestionData.question}
                          </p>
                          <div className="grid grid-cols-1 gap-2">
                            {testQuestionData.options.map((option, index) => (
                              <button
                                key={index}
                                onClick={() => handleTestAnswer(option)}
                                disabled={isLoading}
                                className="inline-flex items-center justify-center gap-2 whitespace-nowrap ring-offset-background focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg]:size-4 [&_svg]:shrink-0 h-9 bg-emerald-500 hover:bg-emerald-600 text-white font-medium py-2 px-3 rounded-lg transition-all duration-200 hover:scale-102 hover:shadow-md border-2 border-emerald-400 text-sm"
                              >
                                <span className="text-base mr-2 font-bold">
                                  {String.fromCharCode(65 + index)}.
                                </span>
                                {option}
                              </button>
                            ))}
                          </div>
                        </div>
                        <div className="flex justify-end pt-2">
                          <button
                            onClick={handleSkipTest}
                            disabled={isLoading}
                            className="inline-flex items-center justify-center gap-2 whitespace-nowrap font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg]:size-4 [&_svg]:shrink-0 border bg-background hover:text-accent-foreground rounded-md border-gray-300 hover:bg-gray-50 text-xs px-3 py-1 h-7"
                          >
                            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round" className="lucide lucide-x w-3 h-3 mr-1">
                              <path d="M18 6 6 18"></path>
                              <path d="m6 6 12 12"></path>
                            </svg>
                            –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å
                          </button>
                        </div>
                      </div>
                    </div>
                  ) : isAudioTaskActive ? (
                    <div className="w-full flex justify-start">
                      <div className="w-full max-w-xl bg-gradient-to-r from-blue-50 to-purple-50 border-2 border-blue-200 rounded-lg p-4 shadow-sm">
                        <div className="flex items-center justify-between">
                          <div className="flex items-center gap-3 min-w-0">
                            <div className="w-8 h-8 bg-blue-100 rounded-full flex items-center justify-center flex-shrink-0">
                              <Mic className="w-4 h-4 text-blue-600" />
                            </div>
                            <div className="min-w-0">
                              <p className="font-medium text-blue-900 text-sm">üéØ –ê—É–¥–∏–æ-–∑–∞–¥–∞–Ω–∏–µ</p>
                              <p className="text-xs text-blue-700 truncate">{audioTaskText}</p>
                            </div>
                          </div>
                          <div className="flex gap-2 flex-shrink-0">
                            <Button
                              onClick={startAudioTaskRecording}
                              disabled={isRecordingAudioTask || isLoading}
                              className="bg-red-500 hover:bg-red-600 text-white animate-pulse text-sm px-3 py-2 h-9"
                              size="sm"
                            >
                            {isRecordingAudioTask ? (
                              <>
                                <Mic className="w-4 h-4 mr-1 animate-pulse" />
                                –°–ª—É—à–∞—é...
                              </>
                            ) : (
                              <>
                                <Mic className="w-4 h-4 mr-1" />
                                üéôÔ∏è –í—ã–ø–æ–ª–Ω–∏—Ç—å
                              </>
                            )}
                            </Button>
                            <Button
                              onClick={() => setIsAudioTaskActive(false)}
                              disabled={isRecordingAudioTask || isLoading}
                              variant="outline"
                              size="sm"
                              className="border-gray-300 hover:bg-gray-50 text-xs px-3 py-1 h-7"
                            >
                              <X className="w-3 h-3 mr-1" />
                              –û—Ç–º–µ–Ω–∞
                            </Button>
                          </div>
                        </div>
                      </div>
                    </div>
                  ) : (
                    <>
                      <Input
                        ref={inputRef}
                        value={inputMessage}
                        onChange={(e) => setInputMessage(e.target.value)}
                        onKeyPress={handleKeyPress}
                        placeholder={
                          isLessonMode && lessonContextManager.getCurrentContext()
                            ? `–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –ø–æ —Ç–µ–º–µ "${lessonContextManager.getCurrentContext()?.currentTopic}"...`
                            : "–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –ø–æ –ª—é–±–æ–π —É—á–µ–±–Ω–æ–π —Ç–µ–º–µ..."
                        }
                        disabled={isLoading || isProcessingFile}
                        className="flex-1"
                      />

                      {/* Voice Chat Button */}
                      <Button
                        variant={isVoiceChatActive ? "default" : "outline"}
                        size="icon"
                        onClick={startVoiceChat}
                        disabled={!isTTSAvailable()}
                        title={isVoiceChatActive ? "–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ –æ–±—â–µ–Ω–∏–µ" : `–ù–∞—á–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ –æ–±—â–µ–Ω–∏–µ —Å AI –£—á–∏—Ç–µ–ª–µ–º${!('webkitSpeechRecognition' in window && 'SpeechRecognition' in window) ? ' (–ë—Ä–∞—É–∑–µ—Ä –º–æ–∂–µ—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏)' : ''}`}
                        className={isVoiceChatActive ? "bg-red-600 hover:bg-red-700 animate-pulse" : ""}
                      >
                        {isVoiceChatActive ? (
                          isListening ? <Mic className="w-4 h-4 animate-pulse text-white" /> : <MicOff className="w-4 h-4" />
                        ) : (
                          <MessageCircle className="w-4 h-4" />
                        )}
                      </Button>

                      <Button
                        onClick={sendMessage}
                        disabled={(!inputMessage.trim() && uploadedFiles.length === 0) || isLoading || isProcessingFile}
                        size="icon"
                      >
                        {isProcessingFile ? (
                          <div className="w-4 h-4 border-2 border-primary border-t-transparent rounded-full animate-spin" />
                        ) : (
                          <Send className="w-4 h-4" />
                        )}
                      </Button>
                    </>
                  )}
            </div>
          </CardContent>
        </Card>
      </div>
    </div>
  );
};

export default Chat;

