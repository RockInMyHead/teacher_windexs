import { OpenAITTS } from './openaiTTS';

/**
 * –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –º–æ–¥—É–ª—å –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
 * - TTS (Text-to-Speech) —Å OpenAI
 * - STT (Speech-to-Text) —Å Web Speech API
 * - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º –∑–∞–ø–∏—Å–∏ –∏ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
 */

export interface VoiceCommOptions {
  language?: string;
  ttsVoice?: 'alloy' | 'echo' | 'fable' | 'onyx' | 'nova' | 'shimmer';
  ttsSpeed?: number;
  continuous?: boolean;
}

export interface VoiceCommCallbacks {
  onListeningStart?: () => void;
  onListeningEnd?: () => void;
  onTranscript?: (text: string, isFinal: boolean) => void;
  onError?: (error: string) => void;
  onPlayStart?: () => void;
  onPlayEnd?: () => void;
}

// Speech Recognition Interface
interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  maxAlternatives: number;
  start(): void;
  stop(): void;
  abort(): void;
  onstart: ((event: Event) => void) | null;
  onend: ((event: Event) => void) | null;
  onresult: ((event: SpeechRecognitionEvent) => void) | null;
  onerror: ((event: SpeechRecognitionErrorEvent) => void) | null;
}

interface SpeechRecognitionEvent extends Event {
  readonly resultIndex: number;
  readonly results: SpeechRecognitionResultList;
}

interface SpeechRecognitionResultList {
  readonly length: number;
  item(index: number): SpeechRecognitionResult;
  [index: number]: SpeechRecognitionResult;
}

interface SpeechRecognitionResult {
  readonly length: number;
  readonly isFinal: boolean;
  item(index: number): SpeechRecognitionAlternative;
  [index: number]: SpeechRecognitionAlternative;
}

interface SpeechRecognitionAlternative {
  readonly transcript: string;
  readonly confidence: number;
}

interface SpeechRecognitionErrorEvent extends Event {
  readonly error: string;
  readonly message: string;
}

declare global {
  interface Window {
    SpeechRecognition?: typeof SpeechRecognition;
    webkitSpeechRecognition?: typeof SpeechRecognition;
  }
}

export class VoiceComm {
  private static recognition: SpeechRecognition | null = null;
  private static isListening = false;
  private static isPlaying = false;
  private static currentTranscript = '';
  private static interimTranscript = '';
  private static callbacks: VoiceCommCallbacks = {};
  private static options: VoiceCommOptions = {
    language: 'ru-RU',
    ttsVoice: 'nova',
    ttsSpeed: 1.0,
    continuous: false
  };

  /**
   * –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥—É–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ–±—â–µ–Ω–∏—è
   */
  static init(options: VoiceCommOptions = {}, callbacks: VoiceCommCallbacks = {}): boolean {
    console.log('üé§ Initializing VoiceComm...');

    // –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–ø—Ü–∏–∏ –∏ –∫–æ–ª–ª–±–µ–∫–∏
    this.options = { ...this.options, ...options };
    this.callbacks = callbacks;

    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Speech Recognition
    const SpeechRecognitionAPI = window.SpeechRecognition || window.webkitSpeechRecognition;

    if (!SpeechRecognitionAPI) {
      console.warn('‚ö†Ô∏è Speech Recognition API not available');
      return false;
    }

    this.recognition = new SpeechRecognitionAPI();
    this.setupRecognitionListeners();

    console.log('‚úÖ VoiceComm initialized successfully');
    return true;
  }

  /**
   * –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–ª—É—à–∞—Ç–µ–ª–µ–π –¥–ª—è —Ä–µ—á–µ–≤–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
   */
  private static setupRecognitionListeners(): void {
    if (!this.recognition) return;

    this.recognition.continuous = this.options.continuous || false;
    this.recognition.interimResults = true;
    this.recognition.lang = this.options.language || 'ru-RU';
    this.recognition.maxAlternatives = 1;

    this.recognition.onstart = () => {
      console.log('üéôÔ∏è Speech recognition started');
      this.isListening = true;
      this.currentTranscript = '';
      this.interimTranscript = '';
      this.callbacks.onListeningStart?.();
    };

    this.recognition.onresult = (event: SpeechRecognitionEvent) => {
      this.interimTranscript = '';
      let finalTranscript = '';

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript;
        const confidence = event.results[i][0].confidence;

        if (event.results[i].isFinal) {
          finalTranscript += transcript + ' ';
          console.log(
            `‚úÖ Final: "${transcript}" (confidence: ${(confidence * 100).toFixed(0)}%)`
          );
        } else {
          this.interimTranscript += transcript;
          console.log(`üîÑ Interim: "${transcript}"`);
        }
      }

      // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–Ω—Ç–µ—Ä–∏–º–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
      if (this.interimTranscript) {
        this.callbacks.onTranscript?.(this.interimTranscript, false);
      }

      // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
      if (finalTranscript) {
        this.currentTranscript = finalTranscript.trim();
        this.callbacks.onTranscript?.(this.currentTranscript, true);
      }
    };

    this.recognition.onend = () => {
      console.log('üõë Speech recognition ended');
      this.isListening = false;
      this.callbacks.onListeningEnd?.();
    };

    this.recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
      console.error('‚ùå Speech recognition error:', event.error);
      const errorMessage = this.getErrorMessage(event.error);
      this.callbacks.onError?.(errorMessage);
      this.isListening = false;
    };
  }

  /**
   * –ü–µ—Ä–µ–≤–æ–¥–∏—Ç –∫–æ–¥—ã –æ—à–∏–±–æ–∫ –≤ –ø–æ–Ω—è—Ç–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
   */
  private static getErrorMessage(error: string): string {
    const errorMessages: { [key: string]: string } = {
      'no-speech': '–ù–µ —Å–ª—ã—à—É —Ä–µ—á—å. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≥–æ–≤–æ—Ä–∏—Ç–µ –≥—Ä–æ–º—á–µ.',
      'audio-capture': '–ú–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è.',
      'network': '–û—à–∏–±–∫–∞ —Å–µ—Ç–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ.',
      'aborted': '–ó–∞–ø–∏—Å—å –ø—Ä–µ—Ä–≤–∞–Ω–∞.',
      'service-not-allowed': '–°–µ—Ä–≤–∏—Å —Ä–µ—á–µ–≤–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.'
    };

    return errorMessages[error] || `–û—à–∏–±–∫–∞ —Ä–µ—á–µ–≤–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: ${error}`;
  }

  /**
   * –ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å –≥–æ–ª–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
   */
  static startListening(): boolean {
    if (!this.recognition) {
      console.warn('‚ö†Ô∏è Speech Recognition not initialized');
      return false;
    }

    if (this.isListening) {
      console.warn('‚ö†Ô∏è Already listening');
      return false;
    }

    try {
      console.log('üéôÔ∏è Starting to listen...');
      this.recognition.start();
      return true;
    } catch (error) {
      console.error('‚ùå Error starting recognition:', error);
      return false;
    }
  }

  /**
   * –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å –≥–æ–ª–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
   */
  static stopListening(): void {
    if (!this.recognition || !this.isListening) return;

    console.log('üõë Stopping listening...');
    this.recognition.stop();
  }

  /**
   * –û—Ç–º–µ–Ω–∏—Ç—å –∑–∞–ø–∏—Å—å (abort)
   */
  static abortListening(): void {
    if (!this.recognition || !this.isListening) return;

    console.log('‚ùå Aborting listening...');
    this.recognition.abort();
    this.isListening = false;
  }

  /**
   * –û–∑–≤—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∑–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º —Å –ø–∞—É–∑–∞–º–∏
   */
  static async speakText(text: string, options?: VoiceCommOptions): Promise<void> {
    if (!text || text.trim().length === 0) {
      console.warn('‚ö†Ô∏è Empty text to speak');
      return;
    }

    const mergedOptions = { ...this.options, ...options };

    try {
      this.isPlaying = true;
      this.callbacks.onPlayStart?.();

      console.log('üé§ Starting to speak text (sentence by sentence)...');

      // –†–∞–∑–¥–µ–ª—è–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
      const sentences = this.splitIntoSentences(text);
      console.log(`üìù Split text into ${sentences.length} sentences`);

      // –û–∑–≤—É—á–∏–≤–∞–µ–º –∫–∞–∂–¥–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
      for (let i = 0; i < sentences.length; i++) {
        const sentence = sentences[i].trim();

        if (sentence.length < 3) {
          console.log(`‚è≠Ô∏è Skipping short sentence: "${sentence}"`);
          continue;
        }

        if (!this.isPlaying) {
          console.log('üõë Speaking stopped by user');
          break;
        }

        console.log(`üéµ Speaking sentence ${i + 1}/${sentences.length}: "${sentence.substring(0, 50)}..."`);

        try {
          await OpenAITTS.speak(sentence, {
            voice: mergedOptions.ttsVoice,
            speed: mergedOptions.ttsSpeed
          });

          console.log(`‚úÖ Sentence ${i + 1} completed`);

          // –ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ (–∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ)
          if (i < sentences.length - 1) {
            await this.delay(300);
          }
        } catch (error) {
          console.error(`‚ùå Error speaking sentence ${i + 1}:`, error);
          // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –æ—à–∏–±–∫–∏
          if (error instanceof Error) {
            if (error.message.includes('NotSupportedError') ||
                error.message.includes('not supported') ||
                error.message.includes('Audio API not supported')) {
              console.warn('‚ö†Ô∏è TTS not supported in this environment, skipping...');
              this.callbacks.onError?.('TTS –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤ —ç—Ç–æ–º –±—Ä–∞—É–∑–µ—Ä–µ');
              // –ü—Ä–µ—Ä—ã–≤–∞–µ–º –æ–∑–≤—É—á–∫—É –µ—Å–ª–∏ TTS –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
              break;
            }
          }
          // –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –¥—Ä—É–≥–∏—Ö —Ç–∏–ø–æ–≤ –æ—à–∏–±–æ–∫
        }
      }

      console.log('‚úÖ Text speaking completed');
    } catch (error) {
      console.error('‚ùå Error in speakText:', error);
      this.callbacks.onError?.('–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–∑–≤—É—á–∏–≤–∞–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞');
    } finally {
      this.isPlaying = false;
      this.callbacks.onPlayEnd?.();
    }
  }

  /**
   * –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ–∑–≤—É—á–∏–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
   */
  static stopSpeaking(): void {
    console.log('üîá Stopping TTS...');
    this.isPlaying = false;
    OpenAITTS.stop();
    if (window.speechSynthesis) {
      window.speechSynthesis.cancel();
    }
  }

  /**
   * –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
   */
  private static splitIntoSentences(text: string): string[] {
    // –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ —Ç–æ—á–∫–∞–º, –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –∏ –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –∑–Ω–∞–∫–∞–º
    let sentences = text.split(/[.!?]+/).filter(s => s.trim().length > 0);

    // –ï—Å–ª–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ, –ø—ã—Ç–∞–µ–º—Å—è —Ä–∞–∑–¥–µ–ª–∏—Ç—å –ø–æ –∞–±–∑–∞—Ü–∞–º
    if (sentences.length === 1) {
      sentences = text.split('\n').filter(s => s.trim().length > 0);
    }

    // –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, —Ä–∞–∑–¥–µ–ª—è–µ–º –ø–æ –∑–∞–ø—è—Ç—ã–º (–ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–∞—Ä–∏–∞–Ω—Ç)
    if (sentences.length === 1) {
      sentences = text.split(',').filter(s => s.trim().length > 0);
    }

    return sentences.map(s => s.trim());
  }

  /**
   * –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–¥–µ—Ä–∂–∫–∏
   */
  private static delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  /**
   * –ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å
   */
  static getStatus(): {
    isListening: boolean;
    isPlaying: boolean;
    currentTranscript: string;
    recognitionAvailable: boolean;
  } {
    return {
      isListening: this.isListening,
      isPlaying: this.isPlaying,
      currentTranscript: this.currentTranscript,
      recognitionAvailable: !!this.recognition
    };
  }

  /**
   * –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å API
   */
  static isAvailable(): boolean {
    return !!this.recognition;
  }

  /**
   * –°–±—Ä–æ—Å–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ
   */
  static reset(): void {
    console.log('üîÑ Resetting VoiceComm...');
    this.stopListening();
    this.stopSpeaking();
    this.currentTranscript = '';
    this.interimTranscript = '';
    this.isListening = false;
    this.isPlaying = false;
  }

  /**
   * –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
   */
  static cleanup(): void {
    console.log('üßπ Cleaning up VoiceComm...');
    this.reset();

    if (this.recognition) {
      try {
        this.recognition.abort();
      } catch (error) {
        console.error('Error aborting recognition:', error);
      }
    }

    this.recognition = null;
    this.callbacks = {};
  }
}

/**
 * –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≥–æ–ª–æ—Å–æ–º
 */
export const VoiceUtils = {
  /**
   * –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
   */
  async checkMicrophonePermission(): Promise<boolean> {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      stream.getTracks().forEach(track => track.stop());
      return true;
    } catch (error) {
      console.error('Microphone permission denied:', error);
      return false;
    }
  },

  /**
   * –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∫—É –±—Ä–∞—É–∑–µ—Ä–æ–º
   */
  checkBrowserSupport(): {
    speechRecognition: boolean;
    audioAPI: boolean;
    mediaDevices: boolean;
  } {
    const SpeechRecognitionAPI = window.SpeechRecognition || window.webkitSpeechRecognition;

    return {
      speechRecognition: !!SpeechRecognitionAPI,
      audioAPI: !!window.AudioContext || !!(window as any).webkitAudioContext,
      mediaDevices: !!navigator.mediaDevices
    };
  },

  /**
   * –ü–æ–ª—É—á–∏—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —è–∑—ã–∫–∏
   */
  getSupportedLanguages(): string[] {
    return [
      'ru-RU', // Russian
      'en-US', // English US
      'en-GB', // English GB
      'es-ES', // Spanish
      'fr-FR', // French
      'de-DE', // German
      'zh-CN', // Chinese Simplified
      'ja-JP', // Japanese
      'ko-KR'  // Korean
    ];
  }
};

