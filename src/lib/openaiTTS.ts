import { replaceNumbersInText } from './numbersToWords';

export interface TTSOptions {
  voice?: 'alloy' | 'echo' | 'fable' | 'onyx' | 'nova' | 'shimmer';
  speed?: number;
  model?: 'tts-1' | 'tts-1-hd';
  format?: 'aac' | 'mp3' | 'opus' | 'flac';
}

export class OpenAITTS {
  private static audioContext: AudioContext | null = null;
  private static currentAudio: HTMLAudioElement | null = null;
  private static videoElement: HTMLVideoElement | null = null;
  private static currentAudioUrl: string | null = null;

  // –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π MIME —Ç–∏–ø –¥–ª—è –∞—É–¥–∏–æ —Ñ–æ—Ä–º–∞—Ç–∞
  private static getMimeType(format: string): string {
    switch (format) {
      case 'aac': return 'audio/aac';
      case 'mp3': return 'audio/mpeg';
      case 'opus': return 'audio/opus';
      case 'flac': return 'audio/flac';
      default: return 'audio/mpeg';
    }
  }

  // –û—á–∏—Å—Ç–∏—Ç—å —Ç–µ–∫—Å—Ç –æ—Ç —É–¥–∞—Ä–µ–Ω–∏–π –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è TTS
  private static cleanTextForTTS(text: string): string {
    if (!text) return text;

    // –£–¥–∞–ª—è–µ–º –∑–Ω–∞–∫–∏ —É–¥–∞—Ä–µ–Ω–∏–π (+) –ø–µ—Ä–µ–¥ –≥–ª–∞—Å–Ω—ã–º–∏
    let cleaned = text.replace(/\+([–∞–µ—ë–∏–æ—É—ã—ç—é—è])/gi, '$1');

    // –£–¥–∞–ª—è–µ–º –¥—Ä—É–≥–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –º–µ—à–∞—Ç—å TTS
    cleaned = cleaned.replace(/[¬´¬ª""''""''""]/g, ''); // –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏

    // –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    cleaned = cleaned.replace(/\s+/g, ' ').trim();

    return cleaned;
  }

  static async generateSpeech(text: string, options: TTSOptions = {}): Promise<ArrayBuffer> {
    const {
      voice = 'alloy', // alloy - –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π –º—É–∂—Å–∫–æ–π –≥–æ–ª–æ—Å, —Ö–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ
      speed = 1.0,
      model = 'tts-1',
      format = 'mp3' // MP3 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å–æ –≤—Å–µ–º–∏ –±—Ä–∞—É–∑–µ—Ä–∞–º–∏
    } = options;

    console.log('üé§ generateSpeech called:', {
      textLength: text.length,
      textPreview: text.substring(0, 50) + '...',
      voice,
      speed,
      model
    });

    // –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ü–∏—Ñ—Ä—ã –≤ —Å–ª–æ–≤–∞ –∏ —É–¥–∞–ª—è–µ–º —É–¥–∞—Ä–µ–Ω–∏—è (–∑–Ω–∞–∫–∏ +)
    const processedText = this.cleanTextForTTS(replaceNumbersInText(text));
    console.log('üìù Original text:', text.substring(0, 100) + '...');
    console.log('üìù Processed text:', processedText.substring(0, 100) + '...');
    console.log('üìù Text changed:', text !== processedText);

    console.log('üì° Fetching TTS from:', `${window.location.origin}/api/audio/speech`);
    const response = await fetch(`${window.location.origin}/api/audio/speech`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: model,
        input: processedText,
        voice: voice,
        response_format: format,
        speed: speed,
      }),
    });

    console.log('üì° TTS API response status:', response.status);

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      console.error('‚ùå TTS API error:', errorData);
      throw new Error(`OpenAI TTS API error: ${response.status} ${response.statusText}. ${errorData.error?.message || ''}`);
    }

    const arrayBuffer = await response.arrayBuffer();
    console.log('‚úÖ TTS audio received, size:', arrayBuffer.byteLength, 'bytes');
    return arrayBuffer;
  }

  static async speak(text: string, options: TTSOptions = {}): Promise<void> {
    return this.speakText(text, options);
  }

  static async speakText(text: string, options: TTSOptions = {}): Promise<void> {
    console.log('üéôÔ∏è OpenAI TTS speakText called with text:', text.substring(0, 50) + '...');

    try {
      // –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å OpenAI TTS
      if (!isTTSAvailable()) {
        console.error('‚ùå OpenAI TTS not available - missing API key or browser audio support');
        throw new Error('OpenAI TTS not available: missing API key or browser does not support Audio API');
      }
      console.log('‚úÖ OpenAI TTS is available');

      // Force MP3 format for OpenAI TTS compatibility
      if (!options.format) {
        options.format = 'mp3';
      }
      console.log('üéµ OpenAI TTS using format:', options.format);

      // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—É—â–µ–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ
      this.stop();

      // –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ—á—å
      console.log('üé§ Calling generateSpeech...');
      const audioBuffer = await this.generateSpeech(text, options);
      console.log('‚úÖ generateSpeech completed');

      // OpenAI TTS Priority: Force Web Audio API first, then HTML Audio, then speech synthesis

      console.log('üéµ üéØ PRIORITY: OpenAI TTS - Using Web Audio API (OpenAI voice preferred)...');

      // Always prioritize OpenAI TTS through Web Audio API
      try {
        // Initialize AudioContext for OpenAI TTS
        if (!this.audioContext) {
          this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
          console.log('‚úÖ AudioContext initialized for OpenAI TTS');
        }

        // Ensure AudioContext is running for OpenAI TTS
        if (this.audioContext.state === 'suspended') {
          await this.audioContext.resume();
          console.log('‚úÖ AudioContext resumed for OpenAI TTS');
        }

        // Decode OpenAI TTS audio buffer
        console.log('üîÑ Decoding OpenAI TTS audio buffer...');
        const decodedBuffer = await this.audioContext.decodeAudioData(audioBuffer.slice());
        console.log('‚úÖ OpenAI TTS audio decoded, duration:', decodedBuffer.duration, 'seconds');

        // Create and play OpenAI TTS using Web Audio API
        return new Promise<void>((resolve) => {
          const source = this.audioContext.createBufferSource();
          source.buffer = decodedBuffer;
          source.connect(this.audioContext.destination);

          source.onended = () => {
            console.log('‚úÖ OpenAI TTS Web Audio playback completed successfully');
            this.pauseVideo();
            resolve();
          };

          console.log('‚ñ∂Ô∏è üöÄ Starting OpenAI TTS playback via Web Audio API...');
          source.start(0);
          this.playVideo();
          console.log('‚úÖ OpenAI TTS Web Audio playback started - using OpenAI voice!');
        });

      } catch (webAudioError) {
        console.warn('‚ö†Ô∏è Web Audio API failed for OpenAI TTS:', webAudioError.message);
        console.log('üîÑ OpenAI TTS: Falling back to HTML Audio...');

        // Fallback 1: HTML Audio for OpenAI TTS
        try {
          const mimeType = this.getMimeType(options.format || 'mp3');
      const blob = new Blob([audioBuffer], { type: mimeType });
      const audioUrl = URL.createObjectURL(blob);
      this.currentAudioUrl = audioUrl;
      
      this.currentAudio = new Audio();
      this.currentAudio.src = audioUrl;
      this.currentAudio.volume = 1.0;

          return new Promise<void>((resolve) => {
      const cleanup = () => {
        if (this.currentAudioUrl) {
          URL.revokeObjectURL(this.currentAudioUrl);
          this.currentAudioUrl = null;
        }
      };

      this.currentAudio.onended = () => {
              console.log('‚úÖ OpenAI TTS HTML Audio playback completed');
        this.pauseVideo();
        this.currentAudio = null;
        cleanup();
        resolve();
      };

            this.currentAudio.onerror = () => {
              console.warn('‚ö†Ô∏è HTML Audio failed for OpenAI TTS, using browser speech synthesis...');
              // Fallback 2: Speech synthesis (still trying to preserve OpenAI audio)
              this.fallbackToWAV(audioBuffer, text, resolve, () => resolve(), cleanup);
            };

            // Try HTML Audio playback for OpenAI TTS
            const playPromise = this.currentAudio.play();
            if (playPromise) {
              playPromise.then(() => {
                console.log('‚úÖ OpenAI TTS HTML Audio playback started');
          this.playVideo();
              }).catch(() => {
                console.warn('‚ö†Ô∏è HTML Audio play failed for OpenAI TTS, using browser speech synthesis...');
                // Fallback 2: Speech synthesis
                this.fallbackToWAV(audioBuffer, text, resolve, () => resolve(), cleanup);
              });
            }
          });

        } catch (htmlAudioError) {
          console.warn('‚ö†Ô∏è HTML Audio setup failed for OpenAI TTS:', htmlAudioError.message);
          console.log('üîÑ OpenAI TTS: Using browser speech synthesis as last resort...');

          // Fallback 2: Speech synthesis
          return new Promise<void>((resolve) => {
            this.fallbackToWAV(audioBuffer, text, resolve, () => resolve(), () => {});
          });
        }
      }

    } catch (error) {
      console.error('‚ùå OpenAI TTS error:', error);
      // Don't throw - provide visual feedback instead
      console.log('‚ö†Ô∏è TTS failed completely, providing visual feedback only');
      // Return successfully to prevent app from breaking
      return;
    }
  }

  // –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ ArrayBuffer –≤ base64
  private static arrayBufferToBase64(buffer: ArrayBuffer): string {
    const bytes = new Uint8Array(buffer);
    let binary = '';
    const len = bytes.byteLength;
    for (let i = 0; i < len; i++) {
      binary += String.fromCharCode(bytes[i]);
    }
    return btoa(binary);
  }

  static stop(): void {
    if (this.currentAudio) {
      this.currentAudio.pause();
      this.currentAudio.currentTime = 0;
      this.currentAudio = null;
    }
    if (this.currentAudioUrl) {
      URL.revokeObjectURL(this.currentAudioUrl);
      this.currentAudioUrl = null;
    }
    this.pauseVideo();
  }

  static isPlaying(): boolean {
    return this.currentAudio !== null && !this.currentAudio.paused;
  }

  // Set video element to sync with TTS
  static setVideoElement(video: HTMLVideoElement | null): void {
    this.videoElement = video;
    console.log('üé• Video element set:', !!video);
    
    // Pause video initially
    if (video) {
      video.pause();
    }
  }

  // Play video when TTS starts
  private static playVideo(): void {
    if (this.videoElement) {
      console.log('‚ñ∂Ô∏è Playing video');
      this.videoElement.play().catch((err) => {
        console.warn('‚ö†Ô∏è Could not play video:', err.message);
      });
    }
  }

  // Pause video when TTS stops
  private static pauseVideo(): void {
    if (this.videoElement) {
      console.log('‚è∏Ô∏è Pausing video');
      this.videoElement.pause();
    }
  }


  // Fallback method if MP3 fails - try browser's built-in speech synthesis
  private static async fallbackToSpeechSynthesis(text: string, resolve: () => void, reject: (error: Error) => void) {
    try {
      console.log('üîÑ Falling back to browser speech synthesis...');

      if (!('speechSynthesis' in window)) {
        console.log('‚ö†Ô∏è Speech synthesis not available in browser');
        // Don't reject - just resolve as if speech worked (silent mode)
        resolve();
        return;
      }

      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'ru-RU'; // Russian language
      utterance.rate = 0.9; // Slightly slower than default
      utterance.pitch = 1.0;
      utterance.volume = 1.0;

      // Set up event handlers
      let hasStarted = false;

      utterance.onstart = () => {
        console.log('‚úÖ Speech synthesis started');
        hasStarted = true;
        this.playVideo();
      };

      utterance.onend = () => {
        console.log('‚úÖ Speech synthesis ended');
        this.pauseVideo();
        resolve();
      };

      utterance.onerror = (event) => {
        console.error('‚ùå Speech synthesis error:', event.error, event);

        // If speech synthesis fails due to autoplay policy, just resolve silently
        if (event.error === 'not-allowed' || event.error === 'interrupted') {
          console.log('‚ö†Ô∏è Speech blocked by browser policy, continuing silently');
          resolve();
        } else {
          // For other errors, still resolve but log the issue
          console.log('‚ö†Ô∏è Speech synthesis failed, continuing with visual feedback only');
          resolve();
        }
      };

      // Add timeout as safety net
      const timeout = setTimeout(() => {
        if (!hasStarted) {
          console.log('‚ö†Ô∏è Speech synthesis timeout, continuing silently');
          resolve();
        }
      }, 5000); // 5 second timeout

      utterance.onstart = () => {
        clearTimeout(timeout);
        console.log('‚úÖ Speech synthesis started');
        hasStarted = true;
        this.playVideo();
      };

      utterance.onend = () => {
        clearTimeout(timeout);
        console.log('‚úÖ Speech synthesis ended');
        this.pauseVideo();
        resolve();
      };

      console.log('üé§ Attempting to speak via browser synthesis...');
      window.speechSynthesis.speak(utterance);

    } catch (error) {
      console.error('‚ùå Speech synthesis setup failed:', error);
      // Don't reject - resolve silently so the app continues working
      console.log('‚ö†Ô∏è Speech synthesis failed, continuing with visual feedback only');
      resolve();
    }
  }

  // Fallback to speech synthesis if MP3 fails
  private static async fallbackToWAV(audioBuffer: ArrayBuffer, text: string, resolve: () => void, reject: (error: Error) => void, cleanup: () => void) {
    try {
      console.log('üîÑ Attempting speech synthesis fallback...');

      // Try speech synthesis first (more reliable)
      // Note: this function now always resolves, never rejects
      await this.fallbackToSpeechSynthesis(text, resolve, reject);
    } catch (speechError) {
      console.error('‚ùå All audio fallbacks failed');
      // Resolve anyway to prevent app from breaking
      console.log('‚ö†Ô∏è All audio methods failed, continuing with visual feedback only');
      resolve();
    }
  }
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∞—É–¥–∏–æ —Ñ–æ—Ä–º–∞—Ç–∞
export async function isAudioFormatSupported(format: string): Promise<boolean> {
  if (typeof Audio === 'undefined') return false;

  try {
    const audio = new Audio();
    const mimeType = format === 'aac' ? 'audio/aac' :
                     format === 'mp3' ? 'audio/mpeg' :
                     format === 'opus' ? 'audio/opus' :
                     format === 'flac' ? 'audio/flac' : 'audio/mpeg';

    const canPlay = audio.canPlayType(mimeType);
    console.log(`üéµ Format ${format} (${mimeType}) support:`, canPlay);
    return canPlay !== '';
  } catch (error) {
    console.warn('Error checking audio format support:', error);
    return false;
  }
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ª—É—á—à–µ–≥–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
export async function getBestSupportedFormat(): Promise<string> {
  // MP3 is the most compatible format for Blob URLs across all browsers
  const formats = ['mp3', 'aac', 'opus', 'flac'];

  for (const format of formats) {
    if (await isAudioFormatSupported(format)) {
      console.log(`‚úÖ Best supported format: ${format}`);
      return format;
    }
  }

  console.warn('‚ùå No supported audio formats found, using mp3 as fallback');
  return 'mp3'; // fallback
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ TTS
export function isTTSAvailable(): boolean {
  // –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ API –∫–ª—é—á–∞
  const hasApiKey = !!import.meta.env.VITE_OPENAI_API_KEY;

  // –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É Audio API –≤ –±—Ä–∞—É–∑–µ—Ä–µ
  const hasAudioSupport = typeof Audio !== 'undefined' &&
                         typeof AudioContext !== 'undefined' &&
                         typeof window !== 'undefined';

  return hasApiKey && hasAudioSupport;
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏, —Ä–∞–∑—Ä–µ—à–µ–Ω–æ –ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –∞—É–¥–∏–æ
export async function isAutoplayAllowed(): Promise<boolean> {
  if (typeof Audio === 'undefined') return false;

  try {
    const audio = new Audio();
    audio.volume = 0.01; // –û—á–µ–Ω—å —Ç–∏—Ö–∏–π –∑–≤—É–∫ –¥–ª—è —Ç–µ—Å—Ç–∞
    audio.muted = true;

    // –ü—ã—Ç–∞–µ–º—Å—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏
    await audio.play();
    audio.pause();
    return true;
  } catch (error) {
    return false;
  }
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –∞—É–¥–∏–æ –ø–æ—Å–ª–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
export function activateAudio(): Promise<void> {
  return new Promise(async (resolve, reject) => {
    try {
      console.log('üîä Activating audio context...');

      // Multiple attempts to activate audio
      const activationPromises = [];

      // 1. Activate AudioContext
      if (typeof AudioContext !== 'undefined' || typeof webkitAudioContext !== 'undefined') {
        const activationPromise = (async () => {
          try {
            const AudioContextClass = AudioContext || webkitAudioContext;
            const audioContext = new AudioContextClass();

            if (audioContext.state === 'suspended') {
              await audioContext.resume();
              console.log('‚úÖ AudioContext activated');
            }

            // Test with a short beep
            const oscillator = audioContext.createOscillator();
            const gainNode = audioContext.createGain();

            oscillator.connect(gainNode);
            gainNode.connect(audioContext.destination);

            oscillator.frequency.setValueAtTime(440, audioContext.currentTime);
            oscillator.type = 'sine';
            gainNode.gain.setValueAtTime(0.01, audioContext.currentTime);

            oscillator.start(audioContext.currentTime);
            oscillator.stop(audioContext.currentTime + 0.1);

            return true;
          } catch (error) {
            console.warn('‚ö†Ô∏è AudioContext activation failed:', error);
            return false;
          }
        })();
        activationPromises.push(activationPromise);
      }

      // 2. Test HTML Audio multiple times
      for (let i = 0; i < 3; i++) {
        const htmlAudioPromise = (async () => {
          try {
            const testAudio = new Audio();
            testAudio.volume = 0.01;
            testAudio.muted = true;
            testAudio.src = 'data:audio/wav;base64,UklGRigAAABXQVZFZm10IBIAAAABAAEARKwAAIhYAQACABAAAABkYXRhAgAAAAEA';

            return new Promise<boolean>((resolveAudio) => {
              testAudio.onended = () => {
                console.log(`‚úÖ HTML Audio test ${i + 1} successful`);
                resolveAudio(true);
              };

              testAudio.onerror = () => {
                console.log(`‚ö†Ô∏è HTML Audio test ${i + 1} failed`);
                resolveAudio(false);
              };

              testAudio.play().catch(() => {
                console.log(`‚ö†Ô∏è HTML Audio play ${i + 1} failed`);
                resolveAudio(false);
              });

              // Timeout fallback
              setTimeout(() => resolveAudio(false), 1000);
            });
          } catch (error) {
            console.log(`‚ö†Ô∏è HTML Audio setup ${i + 1} failed:`, error);
            return false;
          }
        })();
        activationPromises.push(htmlAudioPromise);
      }

      // 3. Test speech synthesis
      const speechPromise = (async () => {
        try {
          if ('speechSynthesis' in window) {
            const utterance = new SpeechSynthesisUtterance('test');
            utterance.volume = 0.01;
            utterance.lang = 'ru-RU';

            return new Promise<boolean>((resolveSpeech) => {
              utterance.onstart = () => {
                console.log('‚úÖ Speech synthesis test successful');
                resolveSpeech(true);
              };

              utterance.onend = () => {
                console.log('‚úÖ Speech synthesis test completed');
                resolveSpeech(true);
              };

              utterance.onerror = () => {
                console.log('‚ö†Ô∏è Speech synthesis test failed');
                resolveSpeech(false);
              };

              window.speechSynthesis.speak(utterance);

              // Timeout fallback
              setTimeout(() => resolveSpeech(false), 2000);
            });
          }
          return false;
        } catch (error) {
          console.log('‚ö†Ô∏è Speech synthesis setup failed:', error);
          return false;
        }
      })();
      activationPromises.push(speechPromise);

      // Wait for all activation attempts
      const results = await Promise.all(activationPromises);
      const successCount = results.filter(Boolean).length;

      console.log(`üîä Audio activation results: ${successCount}/${results.length} successful`);

      if (successCount > 0) {
        console.log('‚úÖ Audio activation completed successfully');
        resolve();
      } else {
        console.log('‚ö†Ô∏è All audio activation methods failed');
        resolve(); // Still resolve to continue app functionality
      }

    } catch (error) {
      console.error('‚ùå Audio activation error:', error);
      // Always resolve to prevent app from breaking
      console.log('‚ö†Ô∏è Audio activation failed, continuing without audio');
      resolve();
    }
  });
}
